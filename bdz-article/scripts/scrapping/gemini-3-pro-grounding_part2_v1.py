# pip install huggingface_hub tqdm pandas

import json
import os
import re
from pathlib import Path
from tqdm import tqdm
from huggingface_hub import HfApi, hf_hub_download
from huggingface_hub.utils import EntryNotFoundError, RepositoryNotFoundError

# === –ù–ê–°–¢–†–û–ô–ö–ò ===
INPUT_FILE = "hf_leaderboards.json"  # –¢–≤–æ–π —Ñ–∞–π–ª —Å–æ —Å–ø–∏—Å–∫–æ–º —Å—Å—ã–ª–æ–∫
OUTPUT_DIR = Path("leaderboards_data")
OUTPUT_DIR.mkdir(exist_ok=True)

# –ò—â–µ–º —Ñ–∞–π–ª—ã, –ø–æ—Ö–æ–∂–∏–µ –Ω–∞ —Ç–∞–±–ª–∏—Ü—ã –¥–∞–Ω–Ω—ã—Ö
PRIORITY_FILES = [
    re.compile(r"results\.csv", re.I),
    re.compile(r"leaderboard\.csv", re.I),
    re.compile(r"data\.csv", re.I),
    re.compile(r".*\.csv$", re.I),     # –õ—é–±–æ–π CSV
    re.compile(r".*\.json$", re.I),    # –õ—é–±–æ–π JSON (—á–∞—Å—Ç–æ —Ç–∞–º –∫–æ–Ω—Ñ–∏–≥–∏, –Ω–æ –±—ã–≤–∞—é—Ç –∏ –¥–∞–Ω–Ω—ã–µ)
    re.compile(r".*\.parquet$", re.I)  # Parquet (—Å–∂–∞—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ)
]

def get_repo_id_from_url(url):
    # –ü—Ä–µ–≤—Ä–∞—â–∞–µ–º https://huggingface.co/spaces/Author/Name -> Author/Name
    if "/spaces/" not in url:
        return None
    return url.split("/spaces/")[1]

# === –ó–ê–ì–†–£–ó–ö–ê –°–ü–ò–°–ö–ê ===
with open(INPUT_FILE, "r", encoding="utf-8") as f:
    urls = json.load(f)

api = HfApi()

print(f"üîÑ –ù–∞—á–∏–Ω–∞—é –ø—Ä–æ–≤–µ—Ä–∫—É –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {len(urls)} –ª–∏–¥–µ—Ä–±–æ—Ä–¥–æ–≤...")

stats = {"downloaded": 0, "no_data_found": 0, "errors": 0}

for url in tqdm(urls):
    repo_id = get_repo_id_from_url(url)
    if not repo_id:
        continue

    # –ü–∞–ø–∫–∞ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ª–∏–¥–µ—Ä–±–æ—Ä–¥–∞
    safe_name = repo_id.replace("/", "__")
    local_folder = OUTPUT_DIR / safe_name
    
    # –ï—Å–ª–∏ –º—ã —É–∂–µ —á—Ç–æ-—Ç–æ —Å–∫–∞—á–∞–ª–∏ –æ—Ç—Ç—É–¥–∞ ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º (–∏–ª–∏ —É–±–µ—Ä–∏ —ç—Ç–æ —É—Å–ª–æ–≤–∏–µ, –µ—Å–ª–∏ —Ö–æ—á–µ—à—å –æ–±–Ω–æ–≤–ª—è—Ç—å)
    if local_folder.exists() and any(local_folder.iterdir()):
        continue

    try:
        # 1. –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –≤ Space
        # repo_type="space" ‚Äî —ç—Ç–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ!
        files = api.list_repo_files(repo_id=repo_id, repo_type="space")
        
        target_file = None
        
        # 2. –ò—â–µ–º —Å–∞–º—ã–π –ø–æ–¥—Ö–æ–¥—è—â–∏–π —Ñ–∞–π–ª –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É
        for pattern in PRIORITY_FILES:
            matches = [f for f in files if pattern.match(f)]
            if matches:
                # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –ø–æ–¥—Ö–æ–¥—è—â–∏–π (–æ–±—ã—á–Ω–æ results.csv –∏–ª–∏ leaderboard.csv)
                target_file = matches[0]
                break
        
        if target_file:
            # 3. –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª
            local_folder.mkdir(exist_ok=True)
            downloaded_path = hf_hub_download(
                repo_id=repo_id,
                filename=target_file,
                repo_type="space",
                local_dir=local_folder,
                local_dir_use_symlinks=False
            )
            stats["downloaded"] += 1
        else:
            # –§–∞–π–ª–æ–≤ –¥–∞–Ω–Ω—ã—Ö —è–≤–Ω–æ –Ω–µ –≤–∏–¥–Ω–æ (–≤–æ–∑–º–æ–∂–Ω–æ –¥–∞–Ω–Ω—ã–µ –≥–µ–Ω–µ—Ä—è—Ç—Å—è –Ω–∞ –ª–µ—Ç—É)
            stats["no_data_found"] += 1

    except Exception as e:
        # –ë—ã–≤–∞–µ—Ç, —á—Ç–æ Space —É–¥–∞–ª–µ–Ω –∏–ª–∏ –∑–∞–∫—Ä—ã—Ç
        # print(f"–û—à–∏–±–∫–∞ —Å {repo_id}: {e}")
        stats["errors"] += 1

print("\n=== –û–¢–ß–ï–¢ ===")
print(f"‚úÖ –°–∫–∞—á–∞–Ω–æ —Ñ–∞–π–ª–æ–≤ –¥–∞–Ω–Ω—ã—Ö: {stats['downloaded']}")
print(f"‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ —è–≤–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ (CSV/JSON): {stats['no_data_found']}")
print(f"‚ùå –û—à–∏–±–∫–∏ –¥–æ—Å—Ç—É–ø–∞/—É–¥–∞–ª–µ–Ω—ã: {stats['errors']}")
print(f"üìÅ –í—Å–µ —Ñ–∞–π–ª—ã –ª–µ–∂–∞—Ç –≤ –ø–∞–ø–∫–µ: {OUTPUT_DIR}")