import requests
import json
import time

OUTPUT_FILE = "leaderboards_v2.jsonl"

def is_leaderboard_repo(repo):
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∏ –æ–ø–∏—Å–∞–Ω–∏–µ
    text = f"{repo.get('id', '')} {repo.get('description', '')}".lower()
    if 'leaderboard' in text:
        return True

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º README
    try:
        readme_url = f"https://huggingface.co/{repo['id']}/raw/main/README.md"
        resp = requests.get(readme_url, timeout=5)
        if resp.status_code == 200:
            readme_text = resp.text.lower()
            if 'leaderboard' in readme_text:
                return True
    except Exception as e:
        pass  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ README

    return False

def fetch_leaderboards():
    leaderboards = []
    page = 1
    per_page = 20
    total_needed = 100

    # –û—á–∏—â–∞–µ–º —Ñ–∞–π–ª –∏–ª–∏ —Å–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        pass  # –ø—Ä–æ—Å—Ç–æ —Å–æ–∑–¥–∞—ë–º/–æ—á–∏—â–∞–µ–º

    print("üîç Starting search for leaderboard datasets on Hugging Face...")

    while len(leaderboards) < total_needed:
        url = f"https://huggingface.co/api/datasets?sort=modified&limit={per_page}&p={page}"
        try:
            resp = requests.get(url, timeout=10)
        except Exception as e:
            print(f"‚ö†Ô∏è Request failed on page {page}: {e}")
            break

        if resp.status_code != 200:
            print(f"‚ö†Ô∏è API returned {resp.status_code} on page {page}. Stopping.")
            break

        repos = resp.json().get('datasets', [])
        if not repos:
            print("‚ÑπÔ∏è No more datasets returned. Stopping.")
            break

        print(f"üìÑ Processing page {page} ({len(repos)} datasets)...")

        for repo in repos:
            if is_leaderboard_repo(repo):
                result = {
                    "id": repo["id"],
                    "description": repo.get("description"),
                    "lastModified": repo.get("lastModified"),
                    "found_at": time.strftime("%Y-%m-%d %H:%M:%S")
                }
                leaderboards.append(repo["id"])

                # –õ–æ–≥–∏—Ä—É–µ–º –≤ –∫–æ–Ω—Å–æ–ª—å
                print(f"‚úÖ Found #{len(leaderboards)}: {repo['id']}")

                # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º **—Å—Ä–∞–∑—É** –≤ —Ñ–∞–π–ª (—Ä–µ–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è)
                with open(OUTPUT_FILE, "a", encoding="utf-8") as f:
                    f.write(json.dumps(result, ensure_ascii=False) + "\n")

                if len(leaderboards) >= total_needed:
                    break

        page += 1

    print(f"\nüéØ Done! Found {len(leaderboards)} leaderboard datasets.")
    print(f"üíæ Results saved line-by-line to '{OUTPUT_FILE}'")

if __name__ == "__main__":
    fetch_leaderboards()