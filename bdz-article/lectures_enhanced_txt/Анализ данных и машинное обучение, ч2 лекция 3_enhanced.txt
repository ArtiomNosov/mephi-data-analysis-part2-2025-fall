
================================================================================
ФАЙЛ: Анализ данных и машинное обучение, ч2 лекция 3
ИСТОЧНИК: /Users/23108022/Documents/repositories/mephi-data-analysis-part2-2025-fall/bdz-article/lectures/Анализ данных и машинное обучение, ч2 лекция 3.pdf
КОНВЕРТИРОВАНО: pypdf (улучшенная версия)
================================================================================


============================================================

\1

\1отбор признаков (фич) – в этом случае применяются
статистические тесты, чтобы сделать вывод о важности признаков и
отобрать какое-либо их подмножество. Подразумевает потерю
информации и меньшую стабильность.

\1извлечение признаков (фич) – в этом случае создаются новых
независимые признаки в виде комбинации исходных признаков.
Применяются линейные и нелинейные методологии.

============================================================
СТРАНИЦА 7
============================================================
Обучение без учителя. Методы сокращения
размерности. Извлечение признаков
Разложение
матрицы
PCA SVD
Построение графа
соседства
TSNE
\1ngs matrix)

\1это просто λj/p.

\1Гуттмана гласит, что компоненты, основанные на
собственных значениях больше 1, должны быть отобраны. Это
основано на представлении о том, что, поскольку сумма
собственных значений равна p, собственное значение больше 1
представляет компоненту «выше среднего».

============================================================
СТРАНИЦА 25
============================================================
Метод главных компонент (PCA). Пример.
Ирисы Фишера. Визуализация

============================================================
СТРАНИЦА 26
============================================================
Особенности метода главных компонент

\1nel trick).

\1Второй недостаток метода главных компонент состоит в том, что направления, максимизирующие
дисперсию, далеко не всегда максимизируют информативность. Например, переменная с
максимальной дисперсией  может не нести почти никакой информации, в то время как
переменная с минимальной дисперсией позволяет полностью разделить классы. Метод главных
компонент в данном случае отдаст предпочтение первой (менее информативной) переменной.
Вся дополнительная информация, связанная с вектором (например, принадлежность образа к
одному из классов), игнорируется.

============================================================
СТРАНИЦА 28
============================================================
Вращение системы компонент (факторов)

\1ncome Доход: в тысячах евро в год
Beer Пиво: потребление в литрах в год
Wine Вино: потребление в литрах в год
Sex Пол: мужской: –1, или женский: +1
Strength Сила: индекс, основанный на
проверке физических способностей
Region Регион: север : –1, или юг: +1
IQ Коэффициент интеллекта,
измеряемый по стандартному тесту
Пример данных для МГК. Обозначения

============================================================
СТРАНИЦА 35
============================================================

\1