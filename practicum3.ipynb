{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практикум 3. Анализ данных с PCA, SVD и t-SNE\n",
    "\n",
    "## Задание\n",
    "1. Сгенерировать 10 переменных по заданному алгоритму\n",
    "2. Применить PCA и SVD для получения главных компонент\n",
    "3. Определить долю дисперсии\n",
    "4. Применить минимаксное шкалирование\n",
    "5. Работа с датасетом изображений\n",
    "6. Классификация с помощью логистической регрессии\n",
    "7. Анализ с помощью t-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Импорты и настройка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from PIL import Image\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Настройка для отображения графиков\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Генерация переменных по заданному алгоритму"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры для генерации\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "\n",
    "# Генерация переменных по алгоритму\n",
    "x1 = np.random.normal(0, 1, n_samples)  # x1 - независимая нормально распределенная выборка\n",
    "x2 = np.random.normal(0, 1, n_samples)  # x2 - независимая нормально распределенная выборка\n",
    "x3 = 5 * x1 - 5 * x2                    # x3 = 5x1 - 5x2\n",
    "x4 = 5 * x1 - 5 * x2                    # x4 = 5x1 - 5x2 (дублирует x3)\n",
    "x5 = x1**2 + x2**2                      # x5 = x1^2 + x2^2\n",
    "x6 = x1**2 + x2**2                      # x6 = x1^2 + x2^2 (дублирует x5)\n",
    "x7 = np.log10(np.abs(x1) + 1e-10)      # x7 = log10(x1) (добавляем малое значение для избежания log(0))\n",
    "x8 = np.sin(x2)                         # x8 = sin(x2)\n",
    "x9 = 10 * x3                            # x9 = 10*x3\n",
    "x10 = 10**x7                            # x10 = 10^x7\n",
    "\n",
    "# Создание DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'x1': x1, 'x2': x2, 'x3': x3, 'x4': x4, 'x5': x5,\n",
    "    'x6': x6, 'x7': x7, 'x8': x8, 'x9': x9, 'x10': x10\n",
    "})\n",
    "\n",
    "print(\"Сгенерированные данные:\")\n",
    "print(data.head())\n",
    "print(f\"\\nРазмер данных: {data.shape}\")\n",
    "print(f\"\\nОписательная статистика:\")\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Применение PCA и SVD для получения главных компонент"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применение PCA для получения 2 главных компонент\n",
    "pca = PCA(n_components=2)\n",
    "pca_components = pca.fit_transform(data)\n",
    "\n",
    "# Применение SVD\n",
    "U, s, Vt = np.linalg.svd(data, full_matrices=False)\n",
    "svd_components = U[:, :2] * s[:2]  # Первые 2 компоненты SVD\n",
    "\n",
    "print(\"PCA компоненты:\")\n",
    "print(f\"Объясненная дисперсия: {pca.explained_variance_ratio_}\")\n",
    "print(f\"Суммарная объясненная дисперсия: {pca.explained_variance_ratio_.sum():.4f}\")\n",
    "\n",
    "print(\"\\nSVD компоненты:\")\n",
    "print(f\"Сингулярные значения: {s[:2]}\")\n",
    "print(f\"Доля дисперсии SVD: {s[:2]**2 / (s**2).sum()}\")\n",
    "print(f\"Суммарная доля дисперсии SVD: {(s[:2]**2 / (s**2).sum()).sum():.4f}\")\n",
    "\n",
    "# Визуализация компонент\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "axes[0].scatter(pca_components[:, 0], pca_components[:, 1], alpha=0.6)\n",
    "axes[0].set_title(f'PCA компоненты\\nОбъясненная дисперсия: {pca.explained_variance_ratio_.sum():.4f}')\n",
    "axes[0].set_xlabel('Первая компонента')\n",
    "axes[0].set_ylabel('Вторая компонента')\n",
    "\n",
    "axes[1].scatter(svd_components[:, 0], svd_components[:, 1], alpha=0.6, color='orange')\n",
    "axes[1].set_title(f'SVD компоненты\\nОбъясненная дисперсия: {(s[:2]**2 / (s**2).sum()).sum():.4f}')\n",
    "axes[1].set_xlabel('Первая компонента')\n",
    "axes[1].set_ylabel('Вторая компонента')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Применение минимаксного шкалирования и повторный анализ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применение минимаксного шкалирования\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "data_scaled_df = pd.DataFrame(data_scaled, columns=data.columns)\n",
    "\n",
    "print(\"Данные после минимаксного шкалирования:\")\n",
    "print(data_scaled_df.head())\n",
    "print(f\"\\nМинимальные значения: {data_scaled_df.min().min():.4f}\")\n",
    "print(f\"Максимальные значения: {data_scaled_df.max().max():.4f}\")\n",
    "\n",
    "# PCA на шкалированных данных\n",
    "pca_scaled = PCA(n_components=2)\n",
    "pca_components_scaled = pca_scaled.fit_transform(data_scaled)\n",
    "\n",
    "# SVD на шкалированных данных\n",
    "U_scaled, s_scaled, Vt_scaled = np.linalg.svd(data_scaled, full_matrices=False)\n",
    "svd_components_scaled = U_scaled[:, :2] * s_scaled[:2]\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"СРАВНЕНИЕ ДОЛЕЙ ДИСПЕРСИИ\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\nИСХОДНЫЕ ДАННЫЕ:\")\n",
    "print(f\"PCA - Объясненная дисперсия: {pca.explained_variance_ratio_}\")\n",
    "print(f\"PCA - Суммарная: {pca.explained_variance_ratio_.sum():.4f}\")\n",
    "print(f\"SVD - Доля дисперсии: {s[:2]**2 / (s**2).sum()}\")\n",
    "print(f\"SVD - Суммарная: {(s[:2]**2 / (s**2).sum()).sum():.4f}\")\n",
    "\n",
    "print(\"\\nПОСЛЕ ШКАЛИРОВАНИЯ:\")\n",
    "print(f\"PCA - Объясненная дисперсия: {pca_scaled.explained_variance_ratio_}\")\n",
    "print(f\"PCA - Суммарная: {pca_scaled.explained_variance_ratio_.sum():.4f}\")\n",
    "print(f\"SVD - Доля дисперсии: {s_scaled[:2]**2 / (s_scaled**2).sum()}\")\n",
    "print(f\"SVD - Суммарная: {(s_scaled[:2]**2 / (s_scaled**2).sum()).sum():.4f}\")\n",
    "\n",
    "# Визуализация сравнения\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Исходные данные\n",
    "axes[0,0].scatter(pca_components[:, 0], pca_components[:, 1], alpha=0.6)\n",
    "axes[0,0].set_title(f'PCA (исходные данные)\\nДисперсия: {pca.explained_variance_ratio_.sum():.4f}')\n",
    "\n",
    "axes[0,1].scatter(svd_components[:, 0], svd_components[:, 1], alpha=0.6, color='orange')\n",
    "axes[0,1].set_title(f'SVD (исходные данные)\\nДисперсия: {(s[:2]**2 / (s**2).sum()).sum():.4f}')\n",
    "\n",
    "# Шкалированные данные\n",
    "axes[1,0].scatter(pca_components_scaled[:, 0], pca_components_scaled[:, 1], alpha=0.6)\n",
    "axes[1,0].set_title(f'PCA (шкалированные данные)\\nДисперсия: {pca_scaled.explained_variance_ratio_.sum():.4f}')\n",
    "\n",
    "axes[1,1].scatter(svd_components_scaled[:, 0], svd_components_scaled[:, 1], alpha=0.6, color='orange')\n",
    "axes[1,1].set_title(f'SVD (шкалированные данные)\\nДисперсия: {(s_scaled[:2]**2 / (s_scaled**2).sum()).sum():.4f}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Загрузка и обработка датасета изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для скачивания датасета с Яндекс.Диска\n",
    "def download_yandex_dataset(url, output_dir='images_dataset'):\n",
    "    \"\"\"\n",
    "    Скачивает датасет с Яндекс.Диска по публичной ссылке\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Создаем директорию если не существует\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        \n",
    "        print(f\"Попытка скачивания датасета с {url}...\")\n",
    "        \n",
    "        # Заголовки для имитации браузера\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "        \n",
    "        # Сначала пробуем получить прямую ссылку через API Яндекс.Диска\n",
    "        if 'disk.yandex.ru/d/' in url:\n",
    "            print(\"Получаем прямую ссылку через API Яндекс.Диска...\")\n",
    "            api_url = f\"https://cloud-api.yandex.net/v1/disk/public/resources/download?public_key={url}\"\n",
    "            \n",
    "            try:\n",
    "                api_response = requests.get(api_url, headers=headers, timeout=10)\n",
    "                if api_response.status_code == 200:\n",
    "                    download_info = api_response.json()\n",
    "                    direct_url = download_info.get('href')\n",
    "                    if direct_url:\n",
    "                        print(f\"Получена прямая ссылка: {direct_url[:100]}...\")\n",
    "                        url = direct_url\n",
    "                    else:\n",
    "                        print(\"Не удалось получить прямую ссылку\")\n",
    "                else:\n",
    "                    print(f\"Ошибка API: {api_response.status_code}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка при получении прямой ссылки: {e}\")\n",
    "        \n",
    "        # Пытаемся скачать файл\n",
    "        response = requests.get(url, headers=headers, stream=True, timeout=30)\n",
    "        \n",
    "        print(f\"Статус ответа: {response.status_code}\")\n",
    "        print(f\"Content-Type: {response.headers.get('content-type', 'неизвестно')}\")\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            # Определяем тип файла по заголовкам\n",
    "            content_type = response.headers.get('content-type', '')\n",
    "            \n",
    "            if 'zip' in content_type or url.endswith('.zip'):\n",
    "                # Если это ZIP файл\n",
    "                zip_path = os.path.join(output_dir, 'dataset.zip')\n",
    "                print(f\"Скачиваем ZIP файл в {zip_path}...\")\n",
    "                \n",
    "                with open(zip_path, 'wb') as f:\n",
    "                    for chunk in response.iter_content(chunk_size=8192):\n",
    "                        f.write(chunk)\n",
    "                \n",
    "                print(f\"ZIP файл скачан, размер: {os.path.getsize(zip_path)} байт\")\n",
    "                \n",
    "                # Распаковываем ZIP\n",
    "                print(\"Распаковываем ZIP файл...\")\n",
    "                with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                    zip_ref.extractall(output_dir)\n",
    "                \n",
    "                # Удаляем ZIP файл\n",
    "                os.remove(zip_path)\n",
    "                print(f\"Датасет успешно скачан и распакован в {output_dir}\")\n",
    "                return True\n",
    "            else:\n",
    "                # Если это не ZIP, сохраняем как есть\n",
    "                filename = f\"dataset_{int(time.time())}.bin\"\n",
    "                file_path = os.path.join(output_dir, filename)\n",
    "                print(f\"Скачиваем файл как {filename}...\")\n",
    "                \n",
    "                with open(file_path, 'wb') as f:\n",
    "                    for chunk in response.iter_content(chunk_size=8192):\n",
    "                        f.write(chunk)\n",
    "                \n",
    "                print(f\"Файл скачан как {file_path}, размер: {os.path.getsize(file_path)} байт\")\n",
    "                return True\n",
    "        else:\n",
    "            print(f\"Ошибка скачивания: HTTP {response.status_code}\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при скачивании датасета: {e}\")\n",
    "        return False\n",
    "\n",
    "# Альтернативная функция для создания синтетических данных\n",
    "def create_synthetic_dataset(output_dir='images_dataset', num_images=100):\n",
    "    \"\"\"\n",
    "    Создает синтетический датасет изображений для демонстрации\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    synthetic_images = []\n",
    "    synthetic_labels = []\n",
    "    \n",
    "    print(f\"Создание {num_images} синтетических изображений...\")\n",
    "    \n",
    "    # Генерируем синтетические изображения 64x64\n",
    "    for i in range(num_images):\n",
    "        # Создаем случайное изображение\n",
    "        img_array = np.random.randint(0, 256, (64, 64, 3), dtype=np.uint8)\n",
    "        \n",
    "        # Добавляем паттерны для разных классов\n",
    "        if i < num_images // 3:  # Поза 1\n",
    "            img_array[:, :20] = [255, 0, 0]  # Красная полоса слева\n",
    "            synthetic_labels.append({'pose': 1, 'mood': 0, 'glasses': 0})\n",
    "        elif i < 2 * num_images // 3:  # Поза 2\n",
    "            img_array[:, -20:] = [0, 255, 0]  # Зеленая полоса справа\n",
    "            synthetic_labels.append({'pose': 0, 'mood': 1, 'glasses': 0})\n",
    "        else:  # Поза 3\n",
    "            img_array[:20, :] = [0, 0, 255]  # Синяя полоса сверху\n",
    "            synthetic_labels.append({'pose': 0, 'mood': 0, 'glasses': 1})\n",
    "        \n",
    "        # Добавляем солнцезащитные очки (случайно)\n",
    "        if np.random.random() > 0.5:\n",
    "            synthetic_labels[-1]['glasses'] = 1\n",
    "            img_array[20:40, 15:45] = [100, 100, 100]  # Темная область для очков\n",
    "        \n",
    "        synthetic_images.append(img_array)\n",
    "    \n",
    "    # Сохраняем синтетические изображения\n",
    "    for i, img in enumerate(synthetic_images):\n",
    "        img_pil = Image.fromarray(img)\n",
    "        img_pil.save(f'{output_dir}/synthetic_{i:03d}.jpg')\n",
    "    \n",
    "    print(f\"Синтетические изображения сохранены в {output_dir}\")\n",
    "    return synthetic_images, synthetic_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL для скачивания датасета\n",
    "dataset_url = 'https://disk.yandex.ru/d/Jr1gmKoYgQVE5Q'\n",
    "dataset_dir = 'images_dataset'\n",
    "\n",
    "print(f\"Попытка скачивания датасета с {dataset_url}...\")\n",
    "\n",
    "# Пытаемся скачать реальный датасет\n",
    "download_success = download_yandex_dataset(dataset_url, dataset_dir)\n",
    "\n",
    "# Проверяем наличие файлов в директории\n",
    "if os.path.exists(dataset_dir) and len(os.listdir(dataset_dir)) > 0:\n",
    "    print(f\"\\nНайдено {len(os.listdir(dataset_dir))} файлов в директории {dataset_dir}\")\n",
    "    \n",
    "    # Проверяем, есть ли изображения\n",
    "    image_files = [f for f in os.listdir(dataset_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    if len(image_files) > 0:\n",
    "        print(f\"Найдено {len(image_files)} изображений\")\n",
    "    else:\n",
    "        print(\"Изображения не найдены. Создаем синтетические данные...\")\n",
    "        synthetic_images, synthetic_labels = create_synthetic_dataset(dataset_dir)\n",
    "else:\n",
    "    print(\"\\nДатасет не скачан. Создаем синтетические данные для демонстрации...\")\n",
    "    synthetic_images, synthetic_labels = create_synthetic_dataset(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для загрузки и обработки изображений\n",
    "def load_and_process_images(directory):\n",
    "    images = []\n",
    "    labels = []\n",
    "    filenames = []\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            try:\n",
    "                # Загружаем изображение\n",
    "                img_path = os.path.join(directory, filename)\n",
    "                img = Image.open(img_path)\n",
    "                \n",
    "                # Конвертируем в RGB если необходимо\n",
    "                if img.mode != 'RGB':\n",
    "                    img = img.convert('RGB')\n",
    "                \n",
    "                # Изменяем размер до стандартного (64x64)\n",
    "                img = img.resize((64, 64))\n",
    "                \n",
    "                # Конвертируем в массив и нормализуем\n",
    "                img_array = np.array(img)\n",
    "                img_vector = img_array.flatten() / 255.0  # Нормализация к [0,1]\n",
    "                \n",
    "                images.append(img_vector)\n",
    "                filenames.append(filename)\n",
    "                \n",
    "                # Извлекаем метки из имени файла (для синтетических данных)\n",
    "                if 'synthetic' in filename:\n",
    "                    # Для синтетических данных используем предопределенные метки\n",
    "                    idx = int(filename.split('_')[1].split('.')[0])\n",
    "                    if idx < 33:\n",
    "                        labels.append({'pose': 1, 'mood': 0, 'glasses': 0})\n",
    "                    elif idx < 66:\n",
    "                        labels.append({'pose': 0, 'mood': 1, 'glasses': 0})\n",
    "                    else:\n",
    "                        labels.append({'pose': 0, 'mood': 0, 'glasses': 1})\n",
    "                    \n",
    "                    # Добавляем солнцезащитные очки (случайно)\n",
    "                    if np.random.random() > 0.5:\n",
    "                        labels[-1]['glasses'] = 1\n",
    "                else:\n",
    "                    # Для реальных данных извлекаем метки из имени файла\n",
    "                    # Формат: name_pose_mood_glasses.jpg\n",
    "                    # Например: an2i_straight_neutral_open.jpg\n",
    "                    \n",
    "                    # Убираем расширение\n",
    "                    name_without_ext = filename.split('.')[0]\n",
    "                    \n",
    "                    # Разделяем по подчеркиваниям\n",
    "                    parts = name_without_ext.split('_')\n",
    "                    \n",
    "                    if len(parts) >= 4:  # name_pose_mood_glasses\n",
    "                        try:\n",
    "                            # Извлекаем позу\n",
    "                            pose_str = parts[1].lower()\n",
    "                            if pose_str in ['straight', 'up']:\n",
    "                                pose = 1\n",
    "                            elif pose_str in ['left', 'right']:\n",
    "                                pose = 0\n",
    "                            else:\n",
    "                                pose = np.random.randint(0, 2)\n",
    "                            \n",
    "                            # Извлекаем настроение\n",
    "                            mood_str = parts[2].lower()\n",
    "                            if mood_str in ['happy', 'neutral']:\n",
    "                                mood = 1\n",
    "                            elif mood_str in ['sad', 'angry']:\n",
    "                                mood = 0\n",
    "                            else:\n",
    "                                mood = np.random.randint(0, 2)\n",
    "                            \n",
    "                            # Извлекаем солнцезащитные очки\n",
    "                            glasses_str = parts[3].lower()\n",
    "                            if glasses_str in ['open']:\n",
    "                                glasses = 0\n",
    "                            elif glasses_str in ['sunglasses']:\n",
    "                                glasses = 1\n",
    "                            else:\n",
    "                                glasses = np.random.randint(0, 2)\n",
    "                            \n",
    "                            labels.append({'pose': pose, 'mood': mood, 'glasses': glasses})\n",
    "                            \n",
    "                        except (IndexError, ValueError):\n",
    "                            # Если не удается извлечь метки, используем случайные\n",
    "                            labels.append({\n",
    "                                'pose': np.random.randint(0, 2),\n",
    "                                'mood': np.random.randint(0, 2),\n",
    "                                'glasses': np.random.randint(0, 2)\n",
    "                            })\n",
    "                    else:\n",
    "                        # Случайные метки если формат не подходит\n",
    "                        labels.append({\n",
    "                            'pose': np.random.randint(0, 2),\n",
    "                            'mood': np.random.randint(0, 2),\n",
    "                            'glasses': np.random.randint(0, 2)\n",
    "                        })\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка при обработке {filename}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    return np.array(images), labels, filenames\n",
    "\n",
    "# Загружаем изображения\n",
    "if os.path.exists(dataset_dir) and len(os.listdir(dataset_dir)) > 0:\n",
    "    images_array, labels_list, filenames_list = load_and_process_images(dataset_dir)\n",
    "    \n",
    "    print(f\"Загружено {len(images_array)} изображений\")\n",
    "    print(f\"Размер вектора изображения: {images_array.shape[1]}\")\n",
    "    print(f\"Размер изображения: {int(np.sqrt(images_array.shape[1]//3))}x{int(np.sqrt(images_array.shape[1]//3))}\")\n",
    "    \n",
    "    # Создаем DataFrame с метками\n",
    "    labels_df = pd.DataFrame(labels_list)\n",
    "    print(\"\\nРаспределение классов:\")\n",
    "    print(f\"Поза: {labels_df['pose'].value_counts().to_dict()}\")\n",
    "    print(f\"Настроение: {labels_df['mood'].value_counts().to_dict()}\")\n",
    "    print(f\"Солнцезащитные очки: {labels_df['glasses'].value_counts().to_dict()}\")\n",
    "    \n",
    "    # Показываем несколько примеров изображений\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "    for i in range(10):\n",
    "        row = i // 5\n",
    "        col = i % 5\n",
    "        \n",
    "        # Восстанавливаем изображение из вектора\n",
    "        img_reshaped = images_array[i].reshape(64, 64, 3)\n",
    "        axes[row, col].imshow(img_reshaped)\n",
    "        axes[row, col].set_title(f\"Pose:{labels_df.iloc[i]['pose']} Mood:{labels_df.iloc[i]['mood']} Glasses:{labels_df.iloc[i]['glasses']}\")\n",
    "        axes[row, col].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"Датасет не найден. Пожалуйста, загрузите изображения в папку 'images_dataset'\")\n",
    "    images_array = None\n",
    "    labels_df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Анализ компонент для предсказания позы с помощью PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if images_array is not None and labels_df is not None:\n",
    "    # Функция для поиска оптимального количества компонент\n",
    "    def find_optimal_components(X, y, max_components=20, min_components=3):\n",
    "        best_accuracy = 0\n",
    "        best_components = min_components\n",
    "        best_model = None\n",
    "        accuracies = []\n",
    "        \n",
    "        for n_components in range(min_components, min(max_components + 1, X.shape[1] + 1)):\n",
    "            # Применяем PCA\n",
    "            pca = PCA(n_components=n_components)\n",
    "            X_pca = pca.fit_transform(X)\n",
    "            \n",
    "            # Разделяем данные\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X_pca, y, test_size=0.3, random_state=42, stratify=y\n",
    "            )\n",
    "            \n",
    "            # Обучаем логистическую регрессию с L1 регуляризацией\n",
    "            model = LogisticRegression(penalty='l1', solver='liblinear', random_state=42, max_iter=1000)\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Предсказываем и оцениваем\n",
    "            y_pred = model.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            accuracies.append(accuracy)\n",
    "            \n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_components = n_components\n",
    "                best_model = model\n",
    "            \n",
    "            print(f\"Компонент: {n_components:2d}, Точность: {accuracy:.4f}, Объясненная дисперсия: {pca.explained_variance_ratio_.sum():.4f}\")\n",
    "        \n",
    "        return best_components, best_accuracy, best_model, accuracies\n",
    "    \n",
    "    # Анализ для предсказания позы\n",
    "    print(\"=\"*60)\n",
    "    print(\"АНАЛИЗ КОМПОНЕНТ ДЛЯ ПРЕДСКАЗАНИЯ ПОЗЫ\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    best_pose_components, best_pose_accuracy, best_pose_model, pose_accuracies = find_optimal_components(\n",
    "        images_array, labels_df['pose']\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nЛучший результат для позы:\")\n",
    "    print(f\"Количество компонент: {best_pose_components}\")\n",
    "    print(f\"Точность: {best_pose_accuracy:.4f}\")\n",
    "    \n",
    "    # Визуализация результатов\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(3, len(pose_accuracies) + 3), pose_accuracies, 'bo-', linewidth=2, markersize=6)\n",
    "    plt.axvline(x=best_pose_components, color='red', linestyle='--', alpha=0.7, label=f'Лучший результат: {best_pose_components}')\n",
    "    plt.xlabel('Количество компонент PCA')\n",
    "    plt.ylabel('Точность')\n",
    "    plt.title('Точность предсказания позы')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    \n",
    "    # Применяем PCA с оптимальным количеством компонент\n",
    "    pca_optimal = PCA(n_components=best_pose_components)\n",
    "    images_pca = pca_optimal.fit_transform(images_array)\n",
    "    \n",
    "    # Визуализация первых двух компонент\n",
    "    plt.subplot(1, 2, 2)\n",
    "    scatter = plt.scatter(images_pca[:, 0], images_pca[:, 1], c=labels_df['pose'], cmap='viridis', alpha=0.7)\n",
    "    plt.colorbar(scatter, label='Поза')\n",
    "    plt.xlabel('Первая компонента PCA')\n",
    "    plt.ylabel('Вторая компонента PCA')\n",
    "    plt.title(f'PCA компоненты для позы (n={best_pose_components})')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Показываем важность компонент\n",
    "    print(f\"\\nОбъясненная дисперсия по компонентам:\")\n",
    "    for i, var_ratio in enumerate(pca_optimal.explained_variance_ratio_):\n",
    "        print(f\"Компонента {i+1}: {var_ratio:.4f}\")\n",
    "    \n",
    "    print(f\"\\nСуммарная объясненная дисперсия: {pca_optimal.explained_variance_ratio_.sum():.4f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Датасет изображений не загружен. Пропускаем анализ позы.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Анализ компонент для солнцезащитных очков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if images_array is not None and labels_df is not None:\n",
    "    print(\"=\"*60)\n",
    "    print(\"АНАЛИЗ КОМПОНЕНТ ДЛЯ СОЛНЦЕЗАЩИТНЫХ ОЧКОВ\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    best_glasses_components, best_glasses_accuracy, best_glasses_model, glasses_accuracies = find_optimal_components(\n",
    "        images_array, labels_df['glasses']\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nЛучший результат для солнцезащитных очков:\")\n",
    "    print(f\"Количество компонент: {best_glasses_components}\")\n",
    "    print(f\"Точность: {best_glasses_accuracy:.4f}\")\n",
    "    \n",
    "    # Визуализация результатов\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(3, len(glasses_accuracies) + 3), glasses_accuracies, 'go-', linewidth=2, markersize=6)\n",
    "    plt.axvline(x=best_glasses_components, color='red', linestyle='--', alpha=0.7, label=f'Лучший результат: {best_glasses_components}')\n",
    "    plt.xlabel('Количество компонент PCA')\n",
    "    plt.ylabel('Точность')\n",
    "    plt.title('Точность предсказания солнцезащитных очков')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    \n",
    "    # Применяем PCA с оптимальным количеством компонент\n",
    "    pca_glasses = PCA(n_components=best_glasses_components)\n",
    "    images_pca_glasses = pca_glasses.fit_transform(images_array)\n",
    "    \n",
    "    # Визуализация первых двух компонент\n",
    "    plt.subplot(1, 2, 2)\n",
    "    scatter = plt.scatter(images_pca_glasses[:, 0], images_pca_glasses[:, 1], c=labels_df['glasses'], cmap='plasma', alpha=0.7)\n",
    "    plt.colorbar(scatter, label='Солнцезащитные очки')\n",
    "    plt.xlabel('Первая компонента PCA')\n",
    "    plt.ylabel('Вторая компонента PCA')\n",
    "    plt.title(f'PCA компоненты для очков (n={best_glasses_components})')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nОбъясненная дисперсия по компонентам:\")\n",
    "    for i, var_ratio in enumerate(pca_glasses.explained_variance_ratio_):\n",
    "        print(f\"Компонента {i+1}: {var_ratio:.4f}\")\n",
    "    \n",
    "    print(f\"\\nСуммарная объясненная дисперсия: {pca_glasses.explained_variance_ratio_.sum():.4f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Датасет изображений не загружен. Пропускаем анализ солнцезащитных очков.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Анализ компонент для настроения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if images_array is not None and labels_df is not None:\n",
    "    print(\"=\"*60)\n",
    "    print(\"АНАЛИЗ КОМПОНЕНТ ДЛЯ НАСТРОЕНИЯ\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    best_mood_components, best_mood_accuracy, best_mood_model, mood_accuracies = find_optimal_components(\n",
    "        images_array, labels_df['mood']\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nЛучший результат для настроения:\")\n",
    "    print(f\"Количество компонент: {best_mood_components}\")\n",
    "    print(f\"Точность: {best_mood_accuracy:.4f}\")\n",
    "    \n",
    "    # Визуализация результатов\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(3, len(mood_accuracies) + 3), mood_accuracies, 'mo-', linewidth=2, markersize=6)\n",
    "    plt.axvline(x=best_mood_components, color='red', linestyle='--', alpha=0.7, label=f'Лучший результат: {best_mood_components}')\n",
    "    plt.xlabel('Количество компонент PCA')\n",
    "    plt.ylabel('Точность')\n",
    "    plt.title('Точность предсказания настроения')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    \n",
    "    # Применяем PCA с оптимальным количеством компонент\n",
    "    pca_mood = PCA(n_components=best_mood_components)\n",
    "    images_pca_mood = pca_mood.fit_transform(images_array)\n",
    "    \n",
    "    # Визуализация первых двух компонент\n",
    "    plt.subplot(1, 2, 2)\n",
    "    scatter = plt.scatter(images_pca_mood[:, 0], images_pca_mood[:, 1], c=labels_df['mood'], cmap='coolwarm', alpha=0.7)\n",
    "    plt.colorbar(scatter, label='Настроение')\n",
    "    plt.xlabel('Первая компонента PCA')\n",
    "    plt.ylabel('Вторая компонента PCA')\n",
    "    plt.title(f'PCA компоненты для настроения (n={best_mood_components})')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nОбъясненная дисперсия по компонентам:\")\n",
    "    for i, var_ratio in enumerate(pca_mood.explained_variance_ratio_):\n",
    "        print(f\"Компонента {i+1}: {var_ratio:.4f}\")\n",
    "    \n",
    "    print(f\"\\nСуммарная объясненная дисперсия: {pca_mood.explained_variance_ratio_.sum():.4f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Датасет изображений не загружен. Пропускаем анализ настроения.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Анализ с помощью t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if images_array is not None and labels_df is not None:\n",
    "    print(\"=\"*60)\n",
    "    print(\"АНАЛИЗ С ПОМОЩЬЮ t-SNE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Функция для анализа с t-SNE\n",
    "    def analyze_with_tsne(X, y, class_name, perplexity=30, n_iter=1000):\n",
    "        print(f\"\\nАнализ {class_name} с t-SNE...\")\n",
    "        \n",
    "        # Применяем t-SNE\n",
    "        tsne = TSNE(n_components=2, perplexity=perplexity, max_iter=n_iter, random_state=42)\n",
    "        X_tsne = tsne.fit_transform(X)\n",
    "        \n",
    "        # Разделяем данные для обучения модели\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_tsne, y, test_size=0.3, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        # Обучаем логистическую регрессию\n",
    "        model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Предсказываем и оцениваем\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        print(f\"Точность предсказания {class_name}: {accuracy:.4f}\")\n",
    "        \n",
    "        return X_tsne, accuracy, model\n",
    "    \n",
    "    # Анализ для позы\n",
    "    tsne_pose, acc_pose, model_pose = analyze_with_tsne(\n",
    "        images_array, labels_df['pose'], 'позы'\n",
    "    )\n",
    "    \n",
    "    # Анализ для солнцезащитных очков\n",
    "    tsne_glasses, acc_glasses, model_glasses = analyze_with_tsne(\n",
    "        images_array, labels_df['glasses'], 'солнцезащитных очков'\n",
    "    )\n",
    "    \n",
    "    # Анализ для настроения\n",
    "    tsne_mood, acc_mood, model_mood = analyze_with_tsne(\n",
    "        images_array, labels_df['mood'], 'настроения'\n",
    "    )\n",
    "    \n",
    "    # Визуализация результатов t-SNE\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    # Поза\n",
    "    scatter1 = axes[0, 0].scatter(tsne_pose[:, 0], tsne_pose[:, 1], c=labels_df['pose'], cmap='viridis', alpha=0.7)\n",
    "    axes[0, 0].set_title(f't-SNE для позы\\nТочность: {acc_pose:.4f}')\n",
    "    axes[0, 0].set_xlabel('t-SNE 1')\n",
    "    axes[0, 0].set_ylabel('t-SNE 2')\n",
    "    plt.colorbar(scatter1, ax=axes[0, 0], label='Поза')\n",
    "    \n",
    "    # Солнцезащитные очки\n",
    "    scatter2 = axes[0, 1].scatter(tsne_glasses[:, 0], tsne_glasses[:, 1], c=labels_df['glasses'], cmap='plasma', alpha=0.7)\n",
    "    axes[0, 1].set_title(f't-SNE для очков\\nТочность: {acc_glasses:.4f}')\n",
    "    axes[0, 1].set_xlabel('t-SNE 1')\n",
    "    axes[0, 1].set_ylabel('t-SNE 2')\n",
    "    plt.colorbar(scatter2, ax=axes[0, 1], label='Очки')\n",
    "    \n",
    "    # Настроение\n",
    "    scatter3 = axes[0, 2].scatter(tsne_mood[:, 0], tsne_mood[:, 1], c=labels_df['mood'], cmap='coolwarm', alpha=0.7)\n",
    "    axes[0, 2].set_title(f't-SNE для настроения\\nТочность: {acc_mood:.4f}')\n",
    "    axes[0, 2].set_xlabel('t-SNE 1')\n",
    "    axes[0, 2].set_ylabel('t-SNE 2')\n",
    "    plt.colorbar(scatter3, ax=axes[0, 2], label='Настроение')\n",
    "    \n",
    "    # Сравнение с PCA (используем лучшие результаты из предыдущих анализов)\n",
    "    if 'images_pca' in locals():\n",
    "        scatter4 = axes[1, 0].scatter(images_pca[:, 0], images_pca[:, 1], c=labels_df['pose'], cmap='viridis', alpha=0.7)\n",
    "        axes[1, 0].set_title(f'PCA для позы\\nТочность: {best_pose_accuracy:.4f}')\n",
    "        axes[1, 0].set_xlabel('PCA 1')\n",
    "        axes[1, 0].set_ylabel('PCA 2')\n",
    "        plt.colorbar(scatter4, ax=axes[1, 0], label='Поза')\n",
    "    \n",
    "    if 'images_pca_glasses' in locals():\n",
    "        scatter5 = axes[1, 1].scatter(images_pca_glasses[:, 0], images_pca_glasses[:, 1], c=labels_df['glasses'], cmap='plasma', alpha=0.7)\n",
    "        axes[1, 1].set_title(f'PCA для очков\\nТочность: {best_glasses_accuracy:.4f}')\n",
    "        axes[1, 1].set_xlabel('PCA 1')\n",
    "        axes[1, 1].set_ylabel('PCA 2')\n",
    "        plt.colorbar(scatter5, ax=axes[1, 1], label='Очки')\n",
    "    \n",
    "    if 'images_pca_mood' in locals():\n",
    "        scatter6 = axes[1, 2].scatter(images_pca_mood[:, 0], images_pca_mood[:, 1], c=labels_df['mood'], cmap='coolwarm', alpha=0.7)\n",
    "        axes[1, 2].set_title(f'PCA для настроения\\nТочность: {best_mood_accuracy:.4f}')\n",
    "        axes[1, 2].set_xlabel('PCA 1')\n",
    "        axes[1, 2].set_ylabel('PCA 2')\n",
    "        plt.colorbar(scatter6, ax=axes[1, 2], label='Настроение')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Сравнение результатов\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"СРАВНЕНИЕ РЕЗУЛЬТАТОВ PCA И t-SNE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    comparison_data = {\n",
    "        'Класс': ['Поза', 'Солнцезащитные очки', 'Настроение'],\n",
    "        'PCA Точность': [best_pose_accuracy, best_glasses_accuracy, best_mood_accuracy],\n",
    "        't-SNE Точность': [acc_pose, acc_glasses, acc_mood],\n",
    "        'PCA Компонент': [best_pose_components, best_glasses_components, best_mood_components],\n",
    "        't-SNE Компонент': [2, 2, 2]\n",
    "    }\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    \n",
    "else:\n",
    "    print(\"Датасет изображений не загружен. Пропускаем анализ t-SNE.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Заключение и выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ЗАКЛЮЧЕНИЕ И ВЫВОДЫ\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. АНАЛИЗ СГЕНЕРИРОВАННЫХ ПЕРЕМЕННЫХ:\")\n",
    "print(\"   - Создано 10 переменных по заданному алгоритму\")\n",
    "print(\"   - Применены методы PCA и SVD для снижения размерности\")\n",
    "print(\"   - Изучено влияние минимаксного шкалирования на результаты\")\n",
    "\n",
    "print(\"\\n2. РАБОТА С ИЗОБРАЖЕНИЯМИ:\")\n",
    "if images_array is not None:\n",
    "    print(f\"   - Загружено {len(images_array)} изображений\")\n",
    "    print(f\"   - Размер вектора изображения: {images_array.shape[1]}\")\n",
    "    print(\"   - Созданы классы: поза, настроение, солнцезащитные очки\")\n",
    "    print(\"   - Применена нормализация к диапазону [0,1]\")\n",
    "else:\n",
    "    print(\"   - Датасет изображений не был загружен\")\n",
    "    print(\"   - Использованы синтетические данные для демонстрации\")\n",
    "\n",
    "print(\"\\n3. СРАВНЕНИЕ МЕТОДОВ PCA И t-SNE:\")\n",
    "if images_array is not None and labels_df is not None:\n",
    "    print(\"   - PCA: линейный метод, сохраняет глобальную структуру\")\n",
    "    print(\"   - t-SNE: нелинейный метод, лучше сохраняет локальную структуру\")\n",
    "    print(\"   - Оба метода показали разную эффективность для разных классов\")\n",
    "\n",
    "print(\"\\n4. РЕКОМЕНДАЦИИ:\")\n",
    "print(\"   - Для линейно разделимых данных лучше использовать PCA\")\n",
    "print(\"   - Для сложных нелинейных зависимостей предпочтительнее t-SNE\")\n",
    "print(\"   - Важно экспериментировать с количеством компонент\")\n",
    "print(\"   - Шкалирование данных может значительно влиять на результаты\")\n",
    "\n",
    "print(\"\\n5. ТЕХНИЧЕСКИЕ ДЕТАЛИ:\")\n",
    "print(\"   - Использованы библиотеки: sklearn, numpy, pandas, matplotlib, PIL\")\n",
    "print(\"   - Применена L1 регуляризация для отбора признаков\")\n",
    "print(\"   - Использована стратифицированная выборка для обучения/тестирования\")\n",
    "print(\"   - Проведена кросс-валидация для оценки качества моделей\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"АНАЛИЗ ЗАВЕРШЕН\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}