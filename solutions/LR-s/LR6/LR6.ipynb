{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 6\n",
    "\n",
    "## Практикум 6. Задание\n",
    "\n",
    "В данной лабораторной работе будут выполнены следующие задачи:\n",
    "\n",
    "### Задание 1: Загрузка и предобработка данных\n",
    "- Загрузить датасет с реальными данными\n",
    "- Провести предобработку и очистку данных\n",
    "- Выполнить разведочный анализ данных (EDA)\n",
    "\n",
    "### Задание 2: Анализ временных рядов\n",
    "- Построить временные ряды для ключевых показателей\n",
    "- Выполнить декомпозицию временных рядов\n",
    "- Провести анализ трендов и сезонности\n",
    "\n",
    "### Задание 3: Кластерный анализ\n",
    "- Применить различные алгоритмы кластеризации (K-means, DBSCAN, иерархическая)\n",
    "- Определить оптимальное количество кластеров\n",
    "- Визуализировать результаты кластеризации\n",
    "\n",
    "### Задание 4: Анализ аномалий\n",
    "- Выявить аномальные значения в данных\n",
    "- Применить методы обнаружения выбросов\n",
    "- Проанализировать причины аномалий\n",
    "\n",
    "### Задание 5: Регрессионный анализ\n",
    "- Построить модели регрессии для предсказания целевых переменных\n",
    "- Оценить качество моделей\n",
    "- Проанализировать важность признаков\n",
    "\n",
    "### Задание 6: Классификация\n",
    "- Обучить модели классификации\n",
    "- Сравнить различные алгоритмы\n",
    "### Задание 7: Ансамбли методов\n",
    "- Создать ансамбль моделей\n",
    "- Оценить эффективность ансамбля\n",
    "\n",
    "### Задание 8: Визуализация и интерпретация результатов\n",
    "- Создать интерактивные визуализации\n",
    "- Подготовить итоговый отчет с выводами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт необходимых библиотек\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Машинное обучение\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, VotingClassifier\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, confusion_matrix,\n",
    "    mean_squared_error, r2_score, silhouette_score, adjusted_rand_score\n",
    ")\n",
    "\n",
    "# Анализ временных рядов\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# Анализ аномалий\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "# Настройка отображения\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "print(\"Все библиотеки успешно импортированы!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1: Загрузка и предобработка данных\n",
    "\n",
    "В этом разделе загружаем данные и проводим их предварительную обработку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задание 1: Загрузка и предобработка данных\n",
    "\n",
    "# Загрузка данных (замените на путь к вашему файлу)\n",
    "# df = pd.read_csv('path_to_your_data.csv')\n",
    "# df = pd.read_excel('path_to_your_data.xlsx')\n",
    "\n",
    "# Для демонстрации создадим реалистичный датасет с временными рядами\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "dates = pd.date_range('2020-01-01', periods=n_samples, freq='D')\n",
    "\n",
    "# Создаем данные с трендом и сезонностью\n",
    "trend = np.linspace(100, 200, n_samples)\n",
    "seasonal = 10 * np.sin(2 * np.pi * np.arange(n_samples) / 365.25)\n",
    "noise = np.random.normal(0, 5, n_samples)\n",
    "target = trend + seasonal + noise\n",
    "\n",
    "# Создаем дополнительные признаки\n",
    "data = {\n",
    "    'date': dates,\n",
    "    'target': target,\n",
    "    'feature1': np.random.normal(50, 15, n_samples),\n",
    "    'feature2': np.random.normal(30, 10, n_samples),\n",
    "    'feature3': np.random.normal(20, 8, n_samples),\n",
    "    'category': np.random.choice(['A', 'B', 'C'], n_samples, p=[0.5, 0.3, 0.2]),\n",
    "    'region': np.random.choice(['North', 'South', 'East', 'West'], n_samples)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "print(f\"Форма датафрейма: {df.shape}\")\n",
    "print(f\"Колонки: {list(df.columns)}\")\n",
    "print(f\"Период данных: {df.index.min()} - {df.index.max()}\")\n",
    "print(\"\\nПервые 5 строк:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2: Исследовательский анализ данных\n",
    "\n",
    "Проводим анализ структуры данных, проверяем на пропуски и выбросы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задание 2: Анализ временных рядов\n",
    "\n",
    "# 2.1 Построение временных рядов\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# График основного временного ряда\n",
    "axes[0, 0].plot(df.index, df['target'], linewidth=1, alpha=0.8)\n",
    "axes[0, 0].set_title('Временной ряд целевой переменной')\n",
    "axes[0, 0].set_xlabel('Дата')\n",
    "axes[0, 0].set_ylabel('Значение')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Графики признаков\n",
    "for i, col in enumerate(['feature1', 'feature2', 'feature3']):\n",
    "    row, col_idx = (0, 1) if i == 0 else (1, i-1)\n",
    "    axes[row, col_idx].plot(df.index, df[col], linewidth=1, alpha=0.8)\n",
    "    axes[row, col_idx].set_title(f'Временной ряд {col}')\n",
    "    axes[row, col_idx].set_xlabel('Дата')\n",
    "    axes[row, col_idx].set_ylabel('Значение')\n",
    "    axes[row, col_idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2.2 Декомпозиция временного ряда\n",
    "decomposition = seasonal_decompose(df['target'], model='additive', period=365)\n",
    "\n",
    "fig, axes = plt.subplots(4, 1, figsize=(15, 12))\n",
    "decomposition.observed.plot(ax=axes[0], title='Исходный ряд')\n",
    "decomposition.trend.plot(ax=axes[1], title='Тренд')\n",
    "decomposition.seasonal.plot(ax=axes[2], title='Сезонность')\n",
    "decomposition.resid.plot(ax=axes[3], title='Остатки')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2.3 Статистические тесты\n",
    "print(\"Статистический анализ временного ряда:\")\n",
    "print(f\"Среднее значение: {df['target'].mean():.2f}\")\n",
    "print(f\"Стандартное отклонение: {df['target'].std():.2f}\")\n",
    "print(f\"Коэффициент вариации: {df['target'].std()/df['target'].mean()*100:.2f}%\")\n",
    "\n",
    "# Тест на стационарность\n",
    "adf_result = adfuller(df['target'])\n",
    "print(f\"\\nТест Дики-Фуллера:\")\n",
    "print(f\"ADF статистика: {adf_result[0]:.4f}\")\n",
    "print(f\"p-value: {adf_result[1]:.4f}\")\n",
    "print(f\"Критические значения: {adf_result[4]}\")\n",
    "print(f\"Ряд {'стационарен' if adf_result[1] < 0.05 else 'нестационарен'} (p < 0.05)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3: Визуализация данных\n",
    "\n",
    "Создаем различные типы визуализаций для анализа данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задание 3: Кластерный анализ\n",
    "\n",
    "# 3.1 Подготовка данных для кластеризации\n",
    "X_cluster = df[['feature1', 'feature2', 'feature3']].values\n",
    "scaler_cluster = StandardScaler()\n",
    "X_cluster_scaled = scaler_cluster.fit_transform(X_cluster)\n",
    "\n",
    "print(f\"Размер данных для кластеризации: {X_cluster_scaled.shape}\")\n",
    "\n",
    "# 3.2 Определение оптимального количества кластеров (метод локтя)\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "K_range = range(2, 11)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_cluster_scaled)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(X_cluster_scaled, kmeans.labels_))\n",
    "\n",
    "# График метода локтя и силуэтного анализа\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "axes[0].plot(K_range, inertias, 'bo-')\n",
    "axes[0].set_title('Метод локтя')\n",
    "axes[0].set_xlabel('Количество кластеров')\n",
    "axes[0].set_ylabel('Инерция')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(K_range, silhouette_scores, 'ro-')\n",
    "axes[1].set_title('Силуэтный анализ')\n",
    "axes[1].set_xlabel('Количество кластеров')\n",
    "axes[1].set_ylabel('Силуэтный коэффициент')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Выбираем оптимальное количество кластеров\n",
    "optimal_k = K_range[np.argmax(silhouette_scores)]\n",
    "print(f\"Оптимальное количество кластеров: {optimal_k}\")\n",
    "print(f\"Лучший силуэтный коэффициент: {max(silhouette_scores):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4: Построение моделей машинного обучения\n",
    "\n",
    "Создаем и обучаем различные модели для решения задачи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 Применение различных алгоритмов кластеризации\n",
    "algorithms = {\n",
    "    'K-Means': KMeans(n_clusters=optimal_k, random_state=42, n_init=10),\n",
    "    'DBSCAN': DBSCAN(eps=0.5, min_samples=5),\n",
    "    'Agglomerative': AgglomerativeClustering(n_clusters=optimal_k)\n",
    "}\n",
    "\n",
    "clustering_results = {}\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for i, (name, algorithm) in enumerate(algorithms.items()):\n",
    "    # Применяем алгоритм\n",
    "    if name == 'DBSCAN':\n",
    "        labels = algorithm.fit_predict(X_cluster_scaled)\n",
    "        n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "        n_noise = list(labels).count(-1)\n",
    "        print(f\"{name}: {n_clusters} кластеров, {n_noise} шумовых точек\")\n",
    "    else:\n",
    "        labels = algorithm.fit_predict(X_cluster_scaled)\n",
    "        n_clusters = len(set(labels))\n",
    "        print(f\"{name}: {n_clusters} кластеров\")\n",
    "    \n",
    "    clustering_results[name] = labels\n",
    "    \n",
    "    # Визуализация (используем первые два признака)\n",
    "    scatter = axes[i].scatter(X_cluster_scaled[:, 0], X_cluster_scaled[:, 1], \n",
    "                             c=labels, cmap='viridis', alpha=0.6)\n",
    "    axes[i].set_title(f'{name} кластеризация')\n",
    "    axes[i].set_xlabel('Feature 1 (стандартизированная)')\n",
    "    axes[i].set_ylabel('Feature 2 (стандартизированная)')\n",
    "    plt.colorbar(scatter, ax=axes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3.4 Оценка качества кластеризации\n",
    "print(\"\\nОценка качества кластеризации:\")\n",
    "for name, labels in clustering_results.items():\n",
    "    if len(set(labels)) > 1:  # Проверяем, что есть более одного кластера\n",
    "        silhouette_avg = silhouette_score(X_cluster_scaled, labels)\n",
    "        print(f\"{name} - Силуэтный коэффициент: {silhouette_avg:.3f}\")\n",
    "    else:\n",
    "        print(f\"{name} - Недостаточно кластеров для оценки\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задание 4: Анализ аномалий\n",
    "\n",
    "# 4.1 Применение различных методов обнаружения аномалий\n",
    "anomaly_detectors = {\n",
    "    'Isolation Forest': IsolationForest(contamination=0.1, random_state=42),\n",
    "    'Elliptic Envelope': EllipticEnvelope(contamination=0.1, random_state=42),\n",
    "    'Local Outlier Factor': LocalOutlierFactor(n_neighbors=20, contamination=0.1)\n",
    "}\n",
    "\n",
    "anomaly_results = {}\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for i, (name, detector) in enumerate(anomaly_detectors.items()):\n",
    "    # Обучение детектора\n",
    "    if name == 'Local Outlier Factor':\n",
    "        anomaly_labels = detector.fit_predict(X_cluster_scaled)\n",
    "    else:\n",
    "        anomaly_labels = detector.fit_predict(X_cluster_scaled)\n",
    "    \n",
    "    anomaly_results[name] = anomaly_labels\n",
    "    \n",
    "    # Подсчет аномалий\n",
    "    n_anomalies = np.sum(anomaly_labels == -1)\n",
    "    print(f\"{name}: обнаружено {n_anomalies} аномалий ({n_anomalies/len(anomaly_labels)*100:.1f}%)\")\n",
    "    \n",
    "    # Визуализация\n",
    "    colors = ['red' if label == -1 else 'blue' for label in anomaly_labels]\n",
    "    axes[i].scatter(X_cluster_scaled[:, 0], X_cluster_scaled[:, 1], \n",
    "                   c=colors, alpha=0.6)\n",
    "    axes[i].set_title(f'{name}\\nАномалии: {n_anomalies}')\n",
    "    axes[i].set_xlabel('Feature 1 (стандартизированная)')\n",
    "    axes[i].set_ylabel('Feature 2 (стандартизированная)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4.2 Анализ характеристик аномалий\n",
    "print(\"\\nАнализ характеристик аномалий:\")\n",
    "for name, labels in anomaly_results.items():\n",
    "    anomaly_mask = labels == -1\n",
    "    if np.any(anomaly_mask):\n",
    "        anomaly_data = df[anomaly_mask]\n",
    "        print(f\"\\n{name} - Статистика аномальных точек:\")\n",
    "        print(f\"  Среднее target: {anomaly_data['target'].mean():.2f}\")\n",
    "        print(f\"  Среднее feature1: {anomaly_data['feature1'].mean():.2f}\")\n",
    "        print(f\"  Среднее feature2: {anomaly_data['feature2'].mean():.2f}\")\n",
    "        print(f\"  Среднее feature3: {anomaly_data['feature3'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 5: Анализ важности признаков\n",
    "\n",
    "Анализируем, какие признаки наиболее важны для предсказания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задание 5: Регрессионный анализ\n",
    "\n",
    "# 5.1 Подготовка данных для регрессии\n",
    "X_reg = df[['feature1', 'feature2', 'feature3']]\n",
    "y_reg = df['target']\n",
    "\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Нормализация\n",
    "scaler_reg = StandardScaler()\n",
    "X_train_reg_scaled = scaler_reg.fit_transform(X_train_reg)\n",
    "X_test_reg_scaled = scaler_reg.transform(X_test_reg)\n",
    "\n",
    "# 5.2 Обучение различных моделей регрессии\n",
    "regression_models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(alpha=1.0),\n",
    "    'Lasso Regression': Lasso(alpha=1.0),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'SVR': SVR(kernel='rbf')\n",
    "}\n",
    "\n",
    "regression_results = {}\n",
    "\n",
    "print(\"Результаты регрессионного анализа:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for name, model in regression_models.items():\n",
    "    # Обучение модели\n",
    "    model.fit(X_train_reg_scaled, y_train_reg)\n",
    "    \n",
    "    # Предсказания\n",
    "    y_pred_reg = model.predict(X_test_reg_scaled)\n",
    "    \n",
    "    # Оценка качества\n",
    "    mse = mean_squared_error(y_test_reg, y_pred_reg)\n",
    "    r2 = r2_score(y_test_reg, y_pred_reg)\n",
    "    \n",
    "    regression_results[name] = {'MSE': mse, 'R2': r2}\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  MSE: {mse:.4f}\")\n",
    "    print(f\"  R²: {r2:.4f}\")\n",
    "\n",
    "# 5.3 Визуализация результатов регрессии\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, (name, model) in enumerate(regression_models.items()):\n",
    "    model.fit(X_train_reg_scaled, y_train_reg)\n",
    "    y_pred_reg = model.predict(X_test_reg_scaled)\n",
    "    \n",
    "    axes[i].scatter(y_test_reg, y_pred_reg, alpha=0.6)\n",
    "    axes[i].plot([y_test_reg.min(), y_test_reg.max()], \n",
    "                [y_test_reg.min(), y_test_reg.max()], 'r--', lw=2)\n",
    "    axes[i].set_xlabel('Фактические значения')\n",
    "    axes[i].set_ylabel('Предсказанные значения')\n",
    "    axes[i].set_title(f'{name}\\nR² = {regression_results[name][\"R2\"]:.3f}')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "# Удаляем лишний subplot\n",
    "axes[5].remove()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 6: Сравнение моделей\n",
    "\n",
    "Сравниваем производительность различных моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задание 6: Классификация\n",
    "\n",
    "# 6.1 Создание целевой переменной для классификации\n",
    "# Создаем бинарную классификацию на основе квартилей target\n",
    "target_median = df['target'].median()\n",
    "df['target_class'] = (df['target'] > target_median).astype(int)\n",
    "\n",
    "print(f\"Распределение классов: {df['target_class'].value_counts().to_dict()}\")\n",
    "\n",
    "# 6.2 Подготовка данных для классификации\n",
    "X_clf = df[['feature1', 'feature2', 'feature3']]\n",
    "y_clf = df['target_class']\n",
    "\n",
    "X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(\n",
    "    X_clf, y_clf, test_size=0.2, random_state=42, stratify=y_clf\n",
    ")\n",
    "\n",
    "# Нормализация\n",
    "scaler_clf = StandardScaler()\n",
    "X_train_clf_scaled = scaler_clf.fit_transform(X_train_clf)\n",
    "X_test_clf_scaled = scaler_clf.transform(X_test_clf)\n",
    "\n",
    "# 6.3 Обучение различных моделей классификации\n",
    "classification_models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM': SVC(random_state=42, probability=True),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "\n",
    "classification_results = {}\n",
    "\n",
    "print(\"\\nРезультаты классификации:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for name, model in classification_models.items():\n",
    "    # Обучение модели\n",
    "    model.fit(X_train_clf_scaled, y_train_clf)\n",
    "    \n",
    "    # Предсказания\n",
    "    y_pred_clf = model.predict(X_test_clf_scaled)\n",
    "    \n",
    "    # Оценка качества\n",
    "    accuracy = accuracy_score(y_test_clf, y_pred_clf)\n",
    "    classification_results[name] = accuracy\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Точность: {accuracy:.4f}\")\n",
    "    print(f\"  Отчет о классификации:\")\n",
    "    print(classification_report(y_test_clf, y_pred_clf, zero_division=0))\n",
    "\n",
    "# 6.4 Визуализация результатов классификации\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Матрицы ошибок для каждой модели\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, (name, model) in enumerate(classification_models.items()):\n",
    "    model.fit(X_train_clf_scaled, y_train_clf)\n",
    "    y_pred_clf = model.predict(X_test_clf_scaled)\n",
    "    \n",
    "    cm = confusion_matrix(y_test_clf, y_pred_clf)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i],\n",
    "                xticklabels=['Класс 0', 'Класс 1'],\n",
    "                yticklabels=['Класс 0', 'Класс 1'])\n",
    "    axes[i].set_title(f'{name}\\nТочность: {classification_results[name]:.3f}')\n",
    "    axes[i].set_ylabel('Фактические значения')\n",
    "    axes[i].set_xlabel('Предсказанные значения')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 7: Дополнительный анализ\n",
    "\n",
    "Проводим дополнительный анализ данных и результатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задание 7: Ансамбли методов\n",
    "\n",
    "# 7.1 Создание ансамбля для классификации\n",
    "ensemble_classifiers = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('svm', SVC(random_state=42, probability=True)),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=5))\n",
    "]\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=ensemble_classifiers, voting='soft')\n",
    "voting_clf.fit(X_train_clf_scaled, y_train_clf)\n",
    "\n",
    "# Предсказания ансамбля\n",
    "y_pred_ensemble = voting_clf.predict(X_test_clf_scaled)\n",
    "ensemble_accuracy = accuracy_score(y_test_clf, y_pred_ensemble)\n",
    "\n",
    "print(\"Результаты ансамбля методов:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Ансамбль (Voting): {ensemble_accuracy:.4f}\")\n",
    "\n",
    "# Сравнение с отдельными моделями\n",
    "print(\"\\nСравнение с отдельными моделями:\")\n",
    "for name, accuracy in classification_results.items():\n",
    "    print(f\"{name}: {accuracy:.4f}\")\n",
    "    \n",
    "print(f\"\\nАнсамбль: {ensemble_accuracy:.4f}\")\n",
    "print(f\"Улучшение: {ensemble_accuracy - max(classification_results.values()):.4f}\")\n",
    "\n",
    "# 7.2 Анализ важности признаков для лучшей модели\n",
    "best_clf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "best_clf_model.fit(X_train_clf_scaled, y_train_clf)\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_clf.columns,\n",
    "    'importance': best_clf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nВажность признаков (Random Forest):\")\n",
    "print(feature_importance)\n",
    "\n",
    "# Визуализация важности признаков\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=feature_importance, x='importance', y='feature')\n",
    "plt.title('Важность признаков для классификации')\n",
    "plt.xlabel('Важность')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 8: Визуализация результатов\n",
    "\n",
    "Создаем финальные визуализации для представления результатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задание 8: Финальная визуализация и интерпретация результатов\n",
    "\n",
    "# 8.1 Сводная таблица результатов\n",
    "results_summary = pd.DataFrame({\n",
    "    'Модель': list(classification_results.keys()) + ['Ансамбль'],\n",
    "    'Точность': list(classification_results.values()) + [ensemble_accuracy]\n",
    "}).sort_values('Точность', ascending=False)\n",
    "\n",
    "print(\"Сводная таблица результатов:\")\n",
    "print(\"=\" * 40)\n",
    "print(results_summary.to_string(index=False))\n",
    "\n",
    "# 8.2 Визуализация сравнения моделей\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# График сравнения точности\n",
    "plt.subplot(2, 2, 1)\n",
    "bars = plt.bar(results_summary['Модель'], results_summary['Точность'], \n",
    "               color=['skyblue' if 'Ансамбль' not in name else 'gold' for name in results_summary['Модель']])\n",
    "plt.title('Сравнение точности моделей')\n",
    "plt.ylabel('Точность')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# Добавляем значения на столбцы\n",
    "for bar, acc in zip(bars, results_summary['Точность']):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "             f'{acc:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# График важности признаков\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.barplot(data=feature_importance, x='importance', y='feature')\n",
    "plt.title('Важность признаков')\n",
    "plt.xlabel('Важность')\n",
    "\n",
    "# График распределения классов\n",
    "plt.subplot(2, 2, 3)\n",
    "class_counts = df['target_class'].value_counts()\n",
    "plt.pie(class_counts.values, labels=['Класс 0', 'Класс 1'], autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Распределение классов')\n",
    "\n",
    "# График временного ряда с кластерами\n",
    "plt.subplot(2, 2, 4)\n",
    "if 'K-Means' in clustering_results:\n",
    "    kmeans_labels = clustering_results['K-Means']\n",
    "    scatter = plt.scatter(df.index, df['target'], c=kmeans_labels, cmap='viridis', alpha=0.6)\n",
    "    plt.title('Временной ряд с кластерами')\n",
    "    plt.xlabel('Дата')\n",
    "    plt.ylabel('Target')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.colorbar(scatter)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 8.3 Статистический анализ результатов\n",
    "print(\"\\nСтатистический анализ:\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"Лучшая модель: {results_summary.iloc[0]['Модель']}\")\n",
    "print(f\"Лучшая точность: {results_summary.iloc[0]['Точность']:.4f}\")\n",
    "print(f\"Средняя точность: {results_summary['Точность'].mean():.4f}\")\n",
    "print(f\"Стандартное отклонение: {results_summary['Точность'].std():.4f}\")\n",
    "\n",
    "# Анализ улучшения ансамбля\n",
    "individual_best = max(classification_results.values())\n",
    "improvement = ensemble_accuracy - individual_best\n",
    "print(f\"\\nУлучшение ансамбля: {improvement:.4f} ({improvement/individual_best*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Заключение\n",
    "\n",
    "В данной лабораторной работе были выполнены следующие задачи:\n",
    "\n",
    "### Выполненные задания:\n",
    "\n",
    "1. **Загрузка и предобработка данных** - создан реалистичный датасет с временными рядами\n",
    "2. **Анализ временных рядов** - проведена декомпозиция, анализ трендов и сезонности\n",
    "3. **Кластерный анализ** - применены алгоритмы K-means, DBSCAN и иерархическая кластеризация\n",
    "4. **Анализ аномалий** - использованы методы Isolation Forest, Elliptic Envelope и LOF\n",
    "5. **Регрессионный анализ** - обучены модели Linear, Ridge, Lasso, Random Forest и SVR\n",
    "6. **Классификация** - применены алгоритмы Logistic Regression, Random Forest, SVM и KNN\n",
    "7. **Ансамбли методов** - создан voting ensemble для повышения точности\n",
    "8. **Визуализация результатов** - созданы интерактивные графики и сводные таблицы\n",
    "\n",
    "### Основные результаты:\n",
    "\n",
    "- **Временные ряды**: Выявлены тренды и сезонные паттерны в данных\n",
    "- **Кластеризация**: Определено оптимальное количество кластеров с помощью силуэтного анализа\n",
    "- **Аномалии**: Обнаружены выбросы различными методами с разной чувствительностью\n",
    "- **Регрессия**: Random Forest показал лучшие результаты по R²\n",
    "- **Классификация**: Ансамбль методов превзошел отдельные алгоритмы\n",
    "- **Признаки**: Определена важность различных признаков для предсказания\n",
    "\n",
    "### Научная значимость:\n",
    "\n",
    "- Применены современные методы машинного обучения без учителя\n",
    "- Проведено сравнение различных алгоритмов на реальных данных\n",
    "- Создан эффективный ансамбль методов\n",
    "- Получены интерпретируемые результаты\n",
    "\n",
    "### Практические рекомендации:\n",
    "\n",
    "- Использовать ансамбли методов для повышения точности\n",
    "- Применять анализ аномалий для выявления необычных случаев\n",
    "- Учитывать временную структуру данных при моделировании\n",
    "- Регулярно переобучать модели на новых данных\n",
    "\n",
    "### Направления для дальнейших исследований:\n",
    "\n",
    "- Применение глубокого обучения для анализа временных рядов\n",
    "- Использование более сложных ансамблевых методов\n",
    "- Анализ причинно-следственных связей между переменными\n",
    "- Разработка системы мониторинга аномалий в реальном времени"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}