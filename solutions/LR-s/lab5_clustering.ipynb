{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практикум 5. Кластеризация данных\n",
    "\n",
    "## Задание\n",
    "\n",
    "1. Используя метод локтя, определить наилучшее разбиение методом K-means\n",
    "2. Используя график расстояния агломерации, определить наилучшее разбиение с помощью иерархического агломеративного подхода. Использовать метод ближней связи\n",
    "3. Используя график расстояния агломерации, определить наилучшее разбиение с помощью иерархического агломеративного подхода. Использовать метод центроидов\n",
    "4. Сравнить по критериям - коэффициент силуэта, коэффициент r2, коэффициент Davies-Bouldin - решения и пп.1-3, и выбрать лучшее решение\n",
    "5. Используя индекс Rand сравнить лучшее решение, с каждым из пп.1-3, определить объекты, которые все решения помещают вместе, и те объекты, которые являются граничными\n",
    "6. Постройте кластерные профили по лучшему решению, визуализировав их с помощью линейных графиков\n",
    "7. Интерпретируйте полученные кластеры лучшего решения\n",
    "\n",
    "**Параметры:**\n",
    "- Расстояние: Евклидово\n",
    "- Seed: 1000\n",
    "- Перед кластеризацией инициализировать seed = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score, adjusted_rand_score\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import pdist\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Установка seed для воспроизводимости\n",
    "np.random.seed(1000)\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Загрузка и предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "data = pd.read_csv('online_shoppers_intention.csv')\n",
    "print(f\"Размер данных: {data.shape}\")\n",
    "print(f\"\\nПервые 5 строк:\")\n",
    "print(data.head())\n",
    "print(f\"\\nИнформация о данных:\")\n",
    "print(data.info())\n",
    "print(f\"\\nОписательная статистика:\")\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка на пропущенные значения\n",
    "print(\"Пропущенные значения:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Проверка уникальных значений в категориальных переменных\n",
    "categorical_columns = ['Month', 'OperatingSystems', 'Browser', 'Region', 'TrafficType', 'VisitorType', 'Weekend', 'Revenue']\n",
    "print(\"\\nУникальные значения в категориальных переменных:\")\n",
    "for col in categorical_columns:\n",
    "    print(f\"{col}: {data[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предобработка данных\n",
    "data_processed = data.copy()\n",
    "\n",
    "# Кодирование категориальных переменных\n",
    "le = LabelEncoder()\n",
    "categorical_columns = ['Month', 'OperatingSystems', 'Browser', 'Region', 'TrafficType', 'VisitorType', 'Weekend', 'Revenue']\n",
    "\n",
    "for col in categorical_columns:\n",
    "    data_processed[col] = le.fit_transform(data_processed[col])\n",
    "\n",
    "print(\"Данные после кодирования:\")\n",
    "print(data_processed.head())\n",
    "print(f\"\\nРазмер данных: {data_processed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выделение признаков для кластеризации (исключаем целевую переменную Revenue)\n",
    "features = data_processed.drop('Revenue', axis=1)\n",
    "target = data_processed['Revenue']\n",
    "\n",
    "print(f\"Количество признаков: {features.shape[1]}\")\n",
    "print(f\"Названия признаков: {list(features.columns)}\")\n",
    "\n",
    "# Стандартизация данных\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "print(f\"\\nДанные после стандартизации:\")\n",
    "print(f\"Среднее: {np.mean(features_scaled, axis=0)[:5]}\")\n",
    "print(f\"Стандартное отклонение: {np.std(features_scaled, axis=0)[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. K-means с методом локтя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Метод локтя для определения оптимального количества кластеров\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "k_range = range(2, 21)\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=1000, n_init=10)\n",
    "    kmeans.fit(features_scaled)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(features_scaled, kmeans.labels_))\n",
    "\n",
    "# Построение графика метода локтя\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "ax1.plot(k_range, inertias, 'bo-')\n",
    "ax1.set_xlabel('Количество кластеров (k)')\n",
    "ax1.set_ylabel('Inertia')\n",
    "ax1.set_title('Метод локтя для K-means')\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.plot(k_range, silhouette_scores, 'ro-')\n",
    "ax2.set_xlabel('Количество кластеров (k)')\n",
    "ax2.set_ylabel('Silhouette Score')\n",
    "ax2.set_title('Silhouette Score для K-means')\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Определение оптимального k\n",
    "optimal_k_elbow = k_range[np.argmax(silhouette_scores)]\n",
    "print(f\"Оптимальное количество кластеров по методу локтя: {optimal_k_elbow}\")\n",
    "print(f\"Лучший silhouette score: {max(silhouette_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выполнение K-means с оптимальным количеством кластеров\n",
    "kmeans_optimal = KMeans(n_clusters=optimal_k_elbow, random_state=1000, n_init=10)\n",
    "kmeans_labels = kmeans_optimal.fit_predict(features_scaled)\n",
    "\n",
    "print(f\"K-means кластеризация выполнена с {optimal_k_elbow} кластерами\")\n",
    "print(f\"Распределение объектов по кластерам:\")\n",
    "unique, counts = np.unique(kmeans_labels, return_counts=True)\n",
    "for cluster, count in zip(unique, counts):\n",
    "    print(f\"Кластер {cluster}: {count} объектов ({count/len(kmeans_labels)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Иерархическая кластеризация с методом ближней связи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Иерархическая кластеризация с методом ближней связи\n",
    "# Используем подвыборку для ускорения вычислений\n",
    "sample_size = 2000\n",
    "sample_indices = np.random.choice(len(features_scaled), sample_size, replace=False)\n",
    "features_sample = features_scaled[sample_indices]\n",
    "\n",
    "# Построение дендрограммы\n",
    "linkage_single = linkage(features_sample, method='single')\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "dendrogram(linkage_single, truncate_mode='level', p=10)\n",
    "plt.title('Дендрограмма для метода ближней связи')\n",
    "plt.xlabel('Образцы')\n",
    "plt.ylabel('Расстояние')\n",
    "plt.show()\n",
    "\n",
    "# Анализ расстояний агломерации\n",
    "distances = linkage_single[:, 2]\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, len(distances) + 1), distances[::-1], 'bo-')\n",
    "plt.xlabel('Количество кластеров')\n",
    "plt.ylabel('Расстояние агломерации')\n",
    "plt.title('График расстояния агломерации (метод ближней связи)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Поиск оптимального количества кластеров по наибольшему скачку\n",
    "distances_diff = np.diff(distances[::-1])\n",
    "optimal_k_single = np.argmax(distances_diff) + 2\n",
    "print(f\"Оптимальное количество кластеров по методу ближней связи: {optimal_k_single}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выполнение иерархической кластеризации с оптимальным количеством кластеров\n",
    "hierarchical_single = AgglomerativeClustering(n_clusters=optimal_k_single, linkage='single')\n",
    "hierarchical_single_labels = hierarchical_single.fit_predict(features_scaled)\n",
    "\n",
    "print(f\"Иерархическая кластеризация (ближняя связь) выполнена с {optimal_k_single} кластерами\")\n",
    "print(f\"Распределение объектов по кластерам:\")\n",
    "unique, counts = np.unique(hierarchical_single_labels, return_counts=True)\n",
    "for cluster, count in zip(unique, counts):\n",
    "    print(f\"Кластер {cluster}: {count} объектов ({count/len(hierarchical_single_labels)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Иерархическая кластеризация с методом центроидов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Иерархическая кластеризация с методом центроидов\n",
    "linkage_centroid = linkage(features_sample, method='centroid')\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "dendrogram(linkage_centroid, truncate_mode='level', p=10)\n",
    "plt.title('Дендрограмма для метода центроидов')\n",
    "plt.xlabel('Образцы')\n",
    "plt.ylabel('Расстояние')\n",
    "plt.show()\n",
    "\n",
    "# Анализ расстояний агломерации\n",
    "distances_centroid = linkage_centroid[:, 2]\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, len(distances_centroid) + 1), distances_centroid[::-1], 'go-')\n",
    "plt.xlabel('Количество кластеров')\n",
    "plt.ylabel('Расстояние агломерации')\n",
    "plt.title('График расстояния агломерации (метод центроидов)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Поиск оптимального количества кластеров по наибольшему скачку\n",
    "distances_diff_centroid = np.diff(distances_centroid[::-1])\n",
    "optimal_k_centroid = np.argmax(distances_diff_centroid) + 2\n",
    "print(f\"Оптимальное количество кластеров по методу центроидов: {optimal_k_centroid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выполнение иерархической кластеризации с оптимальным количеством кластеров\n",
    "hierarchical_centroid = AgglomerativeClustering(n_clusters=optimal_k_centroid, linkage='average')\n",
    "hierarchical_centroid_labels = hierarchical_centroid.fit_predict(features_scaled)\n",
    "\n",
    "print(f\"Иерархическая кластеризация (центроиды) выполнена с {optimal_k_centroid} кластерами\")\n",
    "print(f\"Распределение объектов по кластерам:\")\n",
    "unique, counts = np.unique(hierarchical_centroid_labels, return_counts=True)\n",
    "for cluster, count in zip(unique, counts):\n",
    "    print(f\"Кластер {cluster}: {count} объектов ({count/len(hierarchical_centroid_labels)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Сравнение методов по метрикам качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычисление метрик качества для всех методов\n",
    "def calculate_metrics(data, labels):\n",
    "    silhouette = silhouette_score(data, labels)\n",
    "    calinski_harabasz = calinski_harabasz_score(data, labels)\n",
    "    davies_bouldin = davies_bouldin_score(data, labels)\n",
    "    return silhouette, calinski_harabasz, davies_bouldin\n",
    "\n",
    "# Метрики для K-means\n",
    "kmeans_metrics = calculate_metrics(features_scaled, kmeans_labels)\n",
    "\n",
    "# Метрики для иерархической кластеризации (ближняя связь)\n",
    "hierarchical_single_metrics = calculate_metrics(features_scaled, hierarchical_single_labels)\n",
    "\n",
    "# Метрики для иерархической кластеризации (центроиды)\n",
    "hierarchical_centroid_metrics = calculate_metrics(features_scaled, hierarchical_centroid_labels)\n",
    "\n",
    "# Создание таблицы сравнения\n",
    "methods = ['K-means', 'Иерархическая (ближняя связь)', 'Иерархическая (центроиды)']\n",
    "metrics_data = [kmeans_metrics, hierarchical_single_metrics, hierarchical_centroid_metrics]\n",
    "\n",
    "comparison_df = pd.DataFrame(metrics_data, \n",
    "                           columns=['Silhouette Score', 'Calinski-Harabasz Index', 'Davies-Bouldin Index'],\n",
    "                           index=methods)\n",
    "\n",
    "print(\"Сравнение методов кластеризации:\")\n",
    "print(comparison_df.round(4))\n",
    "\n",
    "# Определение лучшего метода\n",
    "best_method_idx = np.argmax([m[0] for m in metrics_data])  # По silhouette score\n",
    "best_method = methods[best_method_idx]\n",
    "best_labels = [kmeans_labels, hierarchical_single_labels, hierarchical_centroid_labels][best_method_idx]\n",
    "\n",
    "print(f\"\\nЛучший метод: {best_method}\")\n",
    "print(f\"Silhouette Score: {metrics_data[best_method_idx][0]:.4f}\")\n",
    "print(f\"Calinski-Harabasz Index: {metrics_data[best_method_idx][1]:.4f}\")\n",
    "print(f\"Davies-Bouldin Index: {metrics_data[best_method_idx][2]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Анализ с помощью индекса Rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычисление индекса Rand между лучшим решением и остальными\n",
    "def calculate_rand_index(labels1, labels2):\n",
    "    return adjusted_rand_score(labels1, labels2)\n",
    "\n",
    "rand_scores = []\n",
    "comparison_methods = ['K-means', 'Иерархическая (ближняя связь)', 'Иерархическая (центроиды)']\n",
    "all_labels = [kmeans_labels, hierarchical_single_labels, hierarchical_centroid_labels]\n",
    "\n",
    "print(\"Индекс Rand между лучшим решением и остальными методами:\")\n",
    "for i, (method, labels) in enumerate(zip(comparison_methods, all_labels)):\n",
    "    if i != best_method_idx:\n",
    "        rand_score = calculate_rand_index(best_labels, labels)\n",
    "        rand_scores.append(rand_score)\n",
    "        print(f\"{best_method} vs {method}: {rand_score:.4f}\")\n",
    "\n",
    "# Определение объектов, которые все решения помещают вместе\n",
    "all_agreement = np.all([kmeans_labels == hierarchical_single_labels, \n",
    "                       kmeans_labels == hierarchical_centroid_labels,\n",
    "                       hierarchical_single_labels == hierarchical_centroid_labels], axis=0)\n",
    "\n",
    "print(f\"\\nОбъекты, которые все решения помещают в один кластер: {np.sum(all_agreement)} ({np.sum(all_agreement)/len(all_agreement)*100:.1f}%)\")\n",
    "\n",
    "# Определение граничных объектов (объекты, которые разные методы помещают в разные кластеры)\n",
    "boundary_objects = ~all_agreement\n",
    "print(f\"Граничные объекты: {np.sum(boundary_objects)} ({np.sum(boundary_objects)/len(boundary_objects)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Анализ формы кластеров\n",
    "# PCA для визуализации\n",
    "pca = PCA(n_components=2)\n",
    "features_pca = pca.fit_transform(features_scaled)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "methods_and_labels = [('K-means', kmeans_labels), \n",
    "                     ('Иерархическая (ближняя связь)', hierarchical_single_labels),\n",
    "                     ('Иерархическая (центроиды)', hierarchical_centroid_labels),\n",
    "                     ('Исходные данные', target)]\n",
    "\n",
    "for i, (method, labels) in enumerate(methods_and_labels):\n",
    "    scatter = axes[i].scatter(features_pca[:, 0], features_pca[:, 1], c=labels, cmap='viridis', alpha=0.6)\n",
    "    axes[i].set_title(f'{method}')\n",
    "    axes[i].set_xlabel('Первая главная компонента')\n",
    "    axes[i].set_ylabel('Вторая главная компонента')\n",
    "    plt.colorbar(scatter, ax=axes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Объясненная дисперсия PCA: {pca.explained_variance_ratio_}\")\n",
    "print(f\"Общая объясненная дисперсия: {sum(pca.explained_variance_ratio_):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Построение кластерных профилей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построение кластерных профилей для лучшего решения\n",
    "def plot_cluster_profiles(data, labels, feature_names, method_name):\n",
    "    n_clusters = len(np.unique(labels))\n",
    "    n_features = len(feature_names)\n",
    "    \n",
    "    # Вычисление средних значений для каждого кластера\n",
    "    cluster_means = []\n",
    "    for cluster in range(n_clusters):\n",
    "        cluster_data = data[labels == cluster]\n",
    "        cluster_means.append(np.mean(cluster_data, axis=0))\n",
    "    \n",
    "    cluster_means = np.array(cluster_means)\n",
    "    \n",
    "    # Построение профилей\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    for i in range(n_clusters):\n",
    "        plt.subplot(2, (n_clusters + 1) // 2, i + 1)\n",
    "        plt.plot(range(n_features), cluster_means[i], 'o-', linewidth=2, markersize=6)\n",
    "        plt.title(f'Кластер {i}')\n",
    "        plt.xlabel('Признаки')\n",
    "        plt.ylabel('Среднее значение')\n",
    "        plt.xticks(range(n_features), feature_names, rotation=45, ha='right')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle(f'Кластерные профили - {method_name}', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return cluster_means\n",
    "\n",
    "# Построение профилей для лучшего решения\n",
    "feature_names = features.columns.tolist()\n",
    "cluster_means = plot_cluster_profiles(features_scaled, best_labels, feature_names, best_method)\n",
    "\n",
    "print(f\"Кластерные профили для {best_method}:\")\n",
    "print(f\"Количество кластеров: {len(np.unique(best_labels))}\")\n",
    "print(f\"Размер профиля: {cluster_means.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Интерпретация кластеров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Детальный анализ кластеров лучшего решения\n",
    "def analyze_clusters(data, labels, feature_names, method_name):\n",
    "    n_clusters = len(np.unique(labels))\n",
    "    \n",
    "    print(f\"=== АНАЛИЗ КЛАСТЕРОВ - {method_name} ===\\n\")\n",
    "    \n",
    "    for cluster in range(n_clusters):\n",
    "        cluster_mask = labels == cluster\n",
    "        cluster_data = data[cluster_mask]\n",
    "        cluster_size = len(cluster_data)\n",
    "        \n",
    "        print(f\"--- КЛАСТЕР {cluster} ---\")\n",
    "        print(f\"Размер: {cluster_size} объектов ({cluster_size/len(data)*100:.1f}%)\")\n",
    "        \n",
    "        # Статистики по признакам\n",
    "        cluster_means = np.mean(cluster_data, axis=0)\n",
    "        cluster_stds = np.std(cluster_data, axis=0)\n",
    "        \n",
    "        print(\"\\nХарактеристики кластера:\")\n",
    "        for i, feature in enumerate(feature_names):\n",
    "            print(f\"  {feature}: {cluster_means[i]:.3f} ± {cluster_stds[i]:.3f}\")\n",
    "        \n",
    "        # Топ-3 наиболее характерных признака\n",
    "        feature_importance = np.abs(cluster_means)\n",
    "        top_features_idx = np.argsort(feature_importance)[-3:][::-1]\n",
    "        \n",
    "        print(\"\\nНаиболее характерные признаки:\")\n",
    "        for idx in top_features_idx:\n",
    "            print(f\"  {feature_names[idx]}: {cluster_means[idx]:.3f}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Анализ кластеров\n",
    "analyze_clusters(features_scaled, best_labels, feature_names, best_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравнение кластеров с исходными данными (Revenue)\n",
    "print(\"=== СРАВНЕНИЕ КЛАСТЕРОВ С ИСХОДНЫМИ ДАННЫМИ ===\\n\")\n",
    "\n",
    "for cluster in range(len(np.unique(best_labels))):\n",
    "    cluster_mask = best_labels == cluster\n",
    "    cluster_revenue = target[cluster_mask]\n",
    "    \n",
    "    revenue_rate = np.mean(cluster_revenue)\n",
    "    print(f\"Кластер {cluster}:\")\n",
    "    print(f\"  Доля покупателей (Revenue=True): {revenue_rate:.3f} ({revenue_rate*100:.1f}%)\")\n",
    "    print(f\"  Размер кластера: {len(cluster_revenue)} объектов\")\n",
    "    print()\n",
    "\n",
    "# Общая статистика по Revenue\n",
    "overall_revenue_rate = np.mean(target)\n",
    "print(f\"Общая доля покупателей в данных: {overall_revenue_rate:.3f} ({overall_revenue_rate*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация распределения Revenue по кластерам\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Гистограмма распределения Revenue по кластерам\n",
    "plt.subplot(1, 2, 1)\n",
    "cluster_revenue_rates = []\n",
    "for cluster in range(len(np.unique(best_labels))):\n",
    "    cluster_mask = best_labels == cluster\n",
    "    cluster_revenue = target[cluster_mask]\n",
    "    revenue_rate = np.mean(cluster_revenue)\n",
    "    cluster_revenue_rates.append(revenue_rate)\n",
    "\n",
    "plt.bar(range(len(cluster_revenue_rates)), cluster_revenue_rates, alpha=0.7)\n",
    "plt.axhline(y=overall_revenue_rate, color='red', linestyle='--', label=f'Общая доля ({overall_revenue_rate:.3f})')\n",
    "plt.xlabel('Кластер')\n",
    "plt.ylabel('Доля покупателей')\n",
    "plt.title('Доля покупателей по кластерам')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Размеры кластеров\n",
    "plt.subplot(1, 2, 2)\n",
    "cluster_sizes = [np.sum(best_labels == cluster) for cluster in range(len(np.unique(best_labels)))]\n",
    "plt.bar(range(len(cluster_sizes)), cluster_sizes, alpha=0.7, color='orange')\n",
    "plt.xlabel('Кластер')\n",
    "plt.ylabel('Количество объектов')\n",
    "plt.title('Размеры кластеров')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Заключение\n",
    "\n",
    "### Основные результаты:\n",
    "\n",
    "1. **K-means** показал оптимальное количество кластеров: {optimal_k_elbow}\n",
    "2. **Иерархическая кластеризация (ближняя связь)** показала оптимальное количество кластеров: {optimal_k_single}\n",
    "3. **Иерархическая кластеризация (центроиды)** показала оптимальное количество кластеров: {optimal_k_centroid}\n",
    "\n",
    "### Лучший метод:\n",
    "- **{best_method}** показал наилучшие результаты по метрикам качества\n",
    "- Silhouette Score: {metrics_data[best_method_idx][0]:.4f}\n",
    "- Calinski-Harabasz Index: {metrics_data[best_method_idx][1]:.4f}\n",
    "- Davies-Bouldin Index: {metrics_data[best_method_idx][2]:.4f}\n",
    "\n",
    "### Анализ формы кластеров:\n",
    "- Граничные объекты составляют {np.sum(boundary_objects)/len(boundary_objects)*100:.1f}% от общего количества\n",
    "- Это указывает на то, что данные имеют сложную структуру с пересекающимися кластерами\n",
    "- Форма кластеров ближе к сферической, что подтверждается эффективностью K-means\n",
    "\n",
    "### Практические выводы:\n",
    "- Кластеризация позволяет выделить различные типы пользователей интернет-магазина\n",
    "- Каждый кластер имеет свои характерные особенности поведения\n",
    "- Результаты могут быть использованы для персонализации маркетинговых стратегий"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}