{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практикум 5. Кластеризация данных\n",
    "\n",
    "## Задание\n",
    "\n",
    "1. Используя метод локтя, определить наилучшее разбиение методом K-means\n",
    "2. Используя график расстояния агломерации, определить наилучшее разбиение с помощью иерархического агломеративного подхода. Использовать метод ближней связи\n",
    "3. Используя график расстояния агломерации, определить наилучшее разбиение с помощью иерархического агломеративного подхода. Использовать метод центроидов\n",
    "4. Сравнить по критериям - коэффициент силуэта, коэффициент r2, коэффициент Davies-Bouldin - решения и пп.1-3, и выбрать лучшее решение\n",
    "5. Используя индекс Rand сравнить лучшее решение, с каждым из пп.1-3, определить объекты, которые все решения помещают вместе, и те объекты, которые являются граничными\n",
    "6. Постройте кластерные профили по лучшему решению, визуализировав их с помощью линейных графиков\n",
    "7. Интерпретируйте полученные кластеры лучшего решения\n",
    "\n",
    "**Параметры:**\n",
    "- Расстояние: Евклидово\n",
    "- Seed: 1000\n",
    "- Перед кластеризацией инициализировать seed = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score, adjusted_rand_score\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import pdist\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Установка seed для воспроизводимости\n",
    "np.random.seed(1000)\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Загрузка и предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "data = pd.read_csv('online_shoppers_intention.csv')\n",
    "print(f\"Размер данных: {data.shape}\")\n",
    "print(f\"\\nПервые 5 строк:\")\n",
    "print(data.head())\n",
    "print(f\"\\nИнформация о данных:\")\n",
    "print(data.info())\n",
    "print(f\"\\nОписательная статистика:\")\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка на пропущенные значения\n",
    "print(\"Пропущенные значения:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Проверка уникальных значений в категориальных переменных\n",
    "categorical_columns = ['Month', 'OperatingSystems', 'Browser', 'Region', 'TrafficType', 'VisitorType', 'Weekend', 'Revenue']\n",
    "print(\"\\nУникальные значения в категориальных переменных:\")\n",
    "for col in categorical_columns:\n",
    "    print(f\"{col}: {data[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предобработка данных\n",
    "data_processed = data.copy()\n",
    "\n",
    "# Кодирование категориальных переменных\n",
    "le = LabelEncoder()\n",
    "categorical_columns = ['Month', 'OperatingSystems', 'Browser', 'Region', 'TrafficType', 'VisitorType', 'Weekend', 'Revenue']\n",
    "\n",
    "for col in categorical_columns:\n",
    "    data_processed[col] = le.fit_transform(data_processed[col])\n",
    "\n",
    "print(\"Данные после кодирования:\")\n",
    "print(data_processed.head())\n",
    "print(f\"\\nРазмер данных: {data_processed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выделение признаков для кластеризации (исключаем целевую переменную Revenue)\n",
    "features = data_processed.drop('Revenue', axis=1)\n",
    "target = data_processed['Revenue']\n",
    "\n",
    "print(f\"Количество признаков: {features.shape[1]}\")\n",
    "print(f\"Названия признаков: {list(features.columns)}\")\n",
    "\n",
    "# Стандартизация данных\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "print(f\"\\nДанные после стандартизации:\")\n",
    "print(f\"Среднее: {np.mean(features_scaled, axis=0)[:5]}\")\n",
    "print(f\"Стандартное отклонение: {np.std(features_scaled, axis=0)[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. K-means с методом локтя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Метод локтя для определения оптимального количества кластеров\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "k_range = range(2, 21)\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=1000, n_init=10)\n",
    "    kmeans.fit(features_scaled)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(features_scaled, kmeans.labels_))\n",
    "\n",
    "# Построение графика метода локтя\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "ax1.plot(k_range, inertias, 'bo-')\n",
    "ax1.set_xlabel('Количество кластеров (k)')\n",
    "ax1.set_ylabel('Inertia')\n",
    "ax1.set_title('Метод локтя для K-means')\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.plot(k_range, silhouette_scores, 'ro-')\n",
    "ax2.set_xlabel('Количество кластеров (k)')\n",
    "ax2.set_ylabel('Silhouette Score')\n",
    "ax2.set_title('Silhouette Score для K-means')\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Определение оптимального k\n",
    "optimal_k_elbow = k_range[np.argmax(silhouette_scores)]\n",
    "print(f\"Оптимальное количество кластеров по методу локтя: {optimal_k_elbow}\")\n",
    "print(f\"Лучший silhouette score: {max(silhouette_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выполнение K-means с оптимальным количеством кластеров\n",
    "kmeans_optimal = KMeans(n_clusters=optimal_k_elbow, random_state=1000, n_init=10)\n",
    "kmeans_labels = kmeans_optimal.fit_predict(features_scaled)\n",
    "\n",
    "print(f\"K-means кластеризация выполнена с {optimal_k_elbow} кластерами\")\n",
    "print(f\"Распределение объектов по кластерам:\")\n",
    "unique, counts = np.unique(kmeans_labels, return_counts=True)\n",
    "for cluster, count in zip(unique, counts):\n",
    "    print(f\"Кластер {cluster}: {count} объектов ({count/len(kmeans_labels)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Иерархическая кластеризация с методом ближней связи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Иерархическая кластеризация с методом ближней связи\n",
    "# Используем подвыборку для ускорения вычислений\n",
    "sample_size = 2000\n",
    "sample_indices = np.random.choice(len(features_scaled), sample_size, replace=False)\n",
    "features_sample = features_scaled[sample_indices]\n",
    "\n",
    "# Построение дендрограммы\n",
    "linkage_single = linkage(features_sample, method='single')\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "dendrogram(linkage_single, truncate_mode='level', p=10)\n",
    "plt.title('Дендрограмма для метода ближней связи')\n",
    "plt.xlabel('Образцы')\n",
    "plt.ylabel('Расстояние')\n",
    "plt.show()\n",
    "\n",
    "# Анализ расстояний агломерации\n",
    "distances = linkage_single[:, 2]\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, len(distances) + 1), distances[::-1], 'bo-')\n",
    "plt.xlabel('Количество кластеров')\n",
    "plt.ylabel('Расстояние агломерации')\n",
    "plt.title('График расстояния агломерации (метод ближней связи)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Поиск оптимального количества кластеров по наибольшему скачку\n",
    "distances_diff = np.diff(distances[::-1])\n",
    "optimal_k_single = np.argmax(distances_diff) + 2\n",
    "print(f\"Оптимальное количество кластеров по методу ближней связи: {optimal_k_single}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выполнение иерархической кластеризации с оптимальным количеством кластеров\n",
    "hierarchical_single = AgglomerativeClustering(n_clusters=optimal_k_single, linkage='single')\n",
    "hierarchical_single_labels = hierarchical_single.fit_predict(features_scaled)\n",
    "\n",
    "print(f\"Иерархическая кластеризация (ближняя связь) выполнена с {optimal_k_single} кластерами\")\n",
    "print(f\"Распределение объектов по кластерам:\")\n",
    "unique, counts = np.unique(hierarchical_single_labels, return_counts=True)\n",
    "for cluster, count in zip(unique, counts):\n",
    "    print(f\"Кластер {cluster}: {count} объектов ({count/len(hierarchical_single_labels)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Иерархическая кластеризация с методом центроидов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Иерархическая кластеризация с методом центроидов\n",
    "linkage_centroid = linkage(features_sample, method='centroid')\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "dendrogram(linkage_centroid, truncate_mode='level', p=10)\n",
    "plt.title('Дендрограмма для метода центроидов')\n",
    "plt.xlabel('Образцы')\n",
    "plt.ylabel('Расстояние')\n",
    "plt.show()\n",
    "\n",
    "# Анализ расстояний агломерации\n",
    "distances_centroid = linkage_centroid[:, 2]\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, len(distances_centroid) + 1), distances_centroid[::-1], 'go-')\n",
    "plt.xlabel('Количество кластеров')\n",
    "plt.ylabel('Расстояние агломерации')\n",
    "plt.title('График расстояния агломерации (метод центроидов)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Поиск оптимального количества кластеров по наибольшему скачку\n",
    "distances_diff_centroid = np.diff(distances_centroid[::-1])\n",
    "optimal_k_centroid = np.argmax(distances_diff_centroid) + 2\n",
    "print(f\"Оптимальное количество кластеров по методу центроидов: {optimal_k_centroid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выполнение иерархической кластеризации с оптимальным количеством кластеров\n",
    "hierarchical_centroid = AgglomerativeClustering(n_clusters=optimal_k_centroid, linkage='average')\n",
    "hierarchical_centroid_labels = hierarchical_centroid.fit_predict(features_scaled)\n",
    "\n",
    "print(f\"Иерархическая кластеризация (центроиды) выполнена с {optimal_k_centroid} кластерами\")\n",
    "print(f\"Распределение объектов по кластерам:\")\n",
    "unique, counts = np.unique(hierarchical_centroid_labels, return_counts=True)\n",
    "for cluster, count in zip(unique, counts):\n",
    "    print(f\"Кластер {cluster}: {count} объектов ({count/len(hierarchical_centroid_labels)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Сравнение методов по критериям качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычисление метрик качества для всех методов\n",
    "def evaluate_clustering(X, labels, method_name):\n",
    "    silhouette = silhouette_score(X, labels)\n",
    "    calinski_harabasz = calinski_harabasz_score(X, labels)\n",
    "    davies_bouldin = davies_bouldin_score(X, labels)\n",
    "    \n",
    "    return {\n",
    "        'Method': method_name,\n",
    "        'Silhouette Score': silhouette,\n",
    "        'Calinski-Harabasz Score (R2)': calinski_harabasz,\n",
    "        'Davies-Bouldin Score': davies_bouldin\n",
    "    }\n",
    "\n",
    "# Оценка всех методов\n",
    "results = []\n",
    "results.append(evaluate_clustering(features_scaled, kmeans_labels, f'K-means (k={optimal_k_elbow})'))\n",
    "results.append(evaluate_clustering(features_scaled, hierarchical_single_labels, f'Hierarchical Single (k={optimal_k_single})'))\n",
    "results.append(evaluate_clustering(features_scaled, hierarchical_centroid_labels, f'Hierarchical Centroid (k={optimal_k_centroid})'))\n",
    "\n",
    "# Создание таблицы результатов\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"Сравнение методов кластеризации:\")\n",
    "print(results_df.round(4))\n",
    "\n",
    "# Определение лучшего метода\n",
    "best_method_idx = results_df['Silhouette Score'].idxmax()\n",
    "best_method = results_df.iloc[best_method_idx]\n",
    "print(f\"\\nЛучший метод: {best_method['Method']}\")\n",
    "print(f\"Silhouette Score: {best_method['Silhouette Score']:.4f}\")\n",
    "print(f\"Calinski-Harabasz Score: {best_method['Calinski-Harabasz Score (R2)']:.4f}\")\n",
    "print(f\"Davies-Bouldin Score: {best_method['Davies-Bouldin Score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация сравнения методов\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "methods = results_df['Method'].tolist()\n",
    "silhouette_scores = results_df['Silhouette Score'].tolist()\n",
    "calinski_scores = results_df['Calinski-Harabasz Score (R2)'].tolist()\n",
    "davies_scores = results_df['Davies-Bouldin Score'].tolist()\n",
    "\n",
    "axes[0].bar(methods, silhouette_scores, color=['skyblue', 'lightcoral', 'lightgreen'])\n",
    "axes[0].set_title('Silhouette Score')\n",
    "axes[0].set_ylabel('Score')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "axes[1].bar(methods, calinski_scores, color=['skyblue', 'lightcoral', 'lightgreen'])\n",
    "axes[1].set_title('Calinski-Harabasz Score (R2)')\n",
    "axes[1].set_ylabel('Score')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "axes[2].bar(methods, davies_scores, color=['skyblue', 'lightcoral', 'lightgreen'])\n",
    "axes[2].set_title('Davies-Bouldin Score')\n",
    "axes[2].set_ylabel('Score')\n",
    "axes[2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Анализ с помощью индекса Rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение лучшего решения и сравнение с другими методами\n",
    "if best_method_idx == 0:\n",
    "    best_labels = kmeans_labels\n",
    "    best_method_name = 'K-means'\n",
    "elif best_method_idx == 1:\n",
    "    best_labels = hierarchical_single_labels\n",
    "    best_method_name = 'Hierarchical Single'\n",
    "else:\n",
    "    best_labels = hierarchical_centroid_labels\n",
    "    best_method_name = 'Hierarchical Centroid'\n",
    "\n",
    "print(f\"Лучший метод: {best_method_name}\")\n",
    "\n",
    "# Вычисление индекса Rand для сравнения с другими методами\n",
    "rand_scores = []\n",
    "comparison_methods = ['K-means', 'Hierarchical Single', 'Hierarchical Centroid']\n",
    "all_labels = [kmeans_labels, hierarchical_single_labels, hierarchical_centroid_labels]\n",
    "\n",
    "for i, (method, labels) in enumerate(zip(comparison_methods, all_labels)):\n",
    "    if not np.array_equal(labels, best_labels):\n",
    "        rand_score = adjusted_rand_score(best_labels, labels)\n",
    "        rand_scores.append(rand_score)\n",
    "        print(f\"Rand Index между {best_method_name} и {method}: {rand_score:.4f}\")\n",
    "    else:\n",
    "        print(f\"{method} - это лучший метод\")\n",
    "\n",
    "if rand_scores:\n",
    "    print(f\"\\nСредний Rand Index: {np.mean(rand_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Анализ согласованности кластеризаций\n",
    "def find_consistent_objects(labels1, labels2, threshold=0.8):\n",
    "    \"\"\"Найти объекты, которые согласованно кластеризуются в обоих методах\"\"\"\n",
    "    consistent = []\n",
    "    for i in range(len(labels1)):\n",
    "        # Подсчет сколько раз объект i попадает в тот же кластер в обоих методах\n",
    "        same_cluster_count = 0\n",
    "        for j in range(len(labels1)):\n",
    "            if i != j:\n",
    "                if (labels1[i] == labels1[j]) == (labels2[i] == labels2[j]):\n",
    "                    same_cluster_count += 1\n",
    "        consistency = same_cluster_count / (len(labels1) - 1)\n",
    "        if consistency >= threshold:\n",
    "            consistent.append(i)\n",
    "    return consistent\n",
    "\n",
    "# Найти согласованные объекты между лучшим методом и остальными\n",
    "print(\"Анализ согласованности кластеризаций:\")\n",
    "for i, (method, labels) in enumerate(zip(comparison_methods, all_labels)):\n",
    "    if not np.array_equal(labels, best_labels):\n",
    "        consistent_objects = find_consistent_objects(best_labels, labels, threshold=0.7)\n",
    "        print(f\"\\nСогласованные объекты между {best_method_name} и {method}: {len(consistent_objects)} ({len(consistent_objects)/len(best_labels)*100:.1f}%)\")\n",
    "        \n",
    "        # Найти граничные объекты (те, которые не согласованы)\n",
    "        all_indices = set(range(len(best_labels)))\n",
    "        boundary_objects = list(all_indices - set(consistent_objects))\n",
    "        print(f\"Граничные объекты: {len(boundary_objects)} ({len(boundary_objects)/len(best_labels)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Построение кластерных профилей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построение кластерных профилей для лучшего решения\n",
    "def plot_cluster_profiles(data, labels, feature_names, n_clusters):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20, 15))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    # Выбираем наиболее важные признаки для визуализации\n",
    "    important_features = ['Administrative', 'Administrative_Duration', 'ProductRelated', 'ProductRelated_Duration', \n",
    "                         'BounceRates', 'ExitRates', 'PageValues', 'SpecialDay']\n",
    "    \n",
    "    for i, feature in enumerate(important_features[:8]):\n",
    "        if i < len(axes):\n",
    "            for cluster in range(n_clusters):\n",
    "                cluster_data = data[labels == cluster][feature]\n",
    "                axes[i].plot([cluster] * len(cluster_data), cluster_data, 'o', alpha=0.6, label=f'Cluster {cluster}')\n",
    "            \n",
    "            axes[i].set_title(f'Профиль кластеров: {feature}')\n",
    "            axes[i].set_xlabel('Кластер')\n",
    "            axes[i].set_ylabel('Значение признака')\n",
    "            axes[i].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Построение профилей\n",
    "n_clusters_best = len(np.unique(best_labels))\n",
    "plot_cluster_profiles(features, best_labels, features.columns, n_clusters_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Детальный анализ кластерных профилей\n",
    "def analyze_cluster_profiles(data, labels, feature_names):\n",
    "    n_clusters = len(np.unique(labels))\n",
    "    \n",
    "    print(f\"Детальный анализ кластерных профилей ({best_method_name}):\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for cluster in range(n_clusters):\n",
    "        cluster_data = data[labels == cluster]\n",
    "        print(f\"\\nКластер {cluster} ({len(cluster_data)} объектов, {len(cluster_data)/len(data)*100:.1f}%):\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        for feature in feature_names:\n",
    "            mean_val = cluster_data[feature].mean()\n",
    "            std_val = cluster_data[feature].std()\n",
    "            print(f\"{feature}: {mean_val:.3f} ± {std_val:.3f}\")\n",
    "\n",
    "analyze_cluster_profiles(features, best_labels, features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация кластеров в 2D пространстве (PCA)\n",
    "pca = PCA(n_components=2)\n",
    "features_pca = pca.fit_transform(features_scaled)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(features_pca[:, 0], features_pca[:, 1], c=best_labels, cmap='viridis', alpha=0.6)\n",
    "plt.colorbar(scatter)\n",
    "plt.title(f'Визуализация кластеров ({best_method_name}) в 2D PCA пространстве')\n",
    "plt.xlabel(f'Первая главная компонента ({pca.explained_variance_ratio_[0]:.2%} дисперсии)')\n",
    "plt.ylabel(f'Вторая главная компонента ({pca.explained_variance_ratio_[1]:.2%} дисперсии)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Объясненная дисперсия: {pca.explained_variance_ratio_.sum():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Интерпретация кластеров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Детальная интерпретация кластеров\n",
    "def interpret_clusters(data, labels, original_data):\n",
    "    n_clusters = len(np.unique(labels))\n",
    "    \n",
    "    print(f\"ИНТЕРПРЕТАЦИЯ КЛАСТЕРОВ ({best_method_name})\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for cluster in range(n_clusters):\n",
    "        cluster_mask = labels == cluster\n",
    "        cluster_data = data[cluster_mask]\n",
    "        cluster_original = original_data[cluster_mask]\n",
    "        \n",
    "        print(f\"\\n{'='*20} КЛАСТЕР {cluster} {'='*20}\")\n",
    "        print(f\"Размер: {len(cluster_data)} объектов ({len(cluster_data)/len(data)*100:.1f}% от общего количества)\")\n",
    "        \n",
    "        # Анализ ключевых характеристик\n",
    "        print(f\"\\nКЛЮЧЕВЫЕ ХАРАКТЕРИСТИКИ:\")\n",
    "        \n",
    "        # Административные страницы\n",
    "        admin_mean = cluster_data['Administrative'].mean()\n",
    "        admin_dur_mean = cluster_data['Administrative_Duration'].mean()\n",
    "        print(f\"• Административные страницы: {admin_mean:.1f} (время: {admin_dur_mean:.1f} сек)\")\n",
    "        \n",
    "        # Информационные страницы\n",
    "        info_mean = cluster_data['Informational'].mean()\n",
    "        info_dur_mean = cluster_data['Informational_Duration'].mean()\n",
    "        print(f\"• Информационные страницы: {info_mean:.1f} (время: {info_dur_mean:.1f} сек)\")\n",
    "        \n",
    "        # Продуктовые страницы\n",
    "        product_mean = cluster_data['ProductRelated'].mean()\n",
    "        product_dur_mean = cluster_data['ProductRelated_Duration'].mean()\n",
    "        print(f\"• Продуктовые страницы: {product_mean:.1f} (время: {product_dur_mean:.1f} сек)\")\n",
    "        \n",
    "        # Показатели качества\n",
    "        bounce_mean = cluster_data['BounceRates'].mean()\n",
    "        exit_mean = cluster_data['ExitRates'].mean()\n",
    "        pageval_mean = cluster_data['PageValues'].mean()\n",
    "        print(f\"• Показатели качества: Bounce={bounce_mean:.3f}, Exit={exit_mean:.3f}, PageValue={pageval_mean:.3f}\")\n",
    "        \n",
    "        # Специальные дни\n",
    "        special_mean = cluster_data['SpecialDay'].mean()\n",
    "        print(f\"• Специальные дни: {special_mean:.3f}\")\n",
    "        \n",
    "        # Демографические характеристики\n",
    "        weekend_pct = cluster_original['Weekend'].mean() * 100\n",
    "        revenue_pct = cluster_original['Revenue'].mean() * 100\n",
    "        print(f\"• Выходные дни: {weekend_pct:.1f}%\")\n",
    "        print(f\"• Конверсия в покупку: {revenue_pct:.1f}%\")\n",
    "        \n",
    "        # Тип посетителя\n",
    "        visitor_types = cluster_original['VisitorType'].value_counts()\n",
    "        print(f\"• Типы посетителей: {dict(visitor_types)}\")\n",
    "        \n",
    "        # Месяцы\n",
    "        months = cluster_original['Month'].value_counts().head(3)\n",
    "        print(f\"• Популярные месяцы: {dict(months)}\")\n",
    "        \n",
    "        # Интерпретация поведения\n",
    "        print(f\"\\nИНТЕРПРЕТАЦИЯ ПОВЕДЕНИЯ:\")\n",
    "        \n",
    "        if admin_mean > data['Administrative'].mean():\n",
    "            print(\"• Высокая активность на административных страницах\")\n",
    "        if product_mean > data['ProductRelated'].mean():\n",
    "            print(\"• Высокая активность на продуктовых страницах\")\n",
    "        if bounce_mean < data['BounceRates'].mean():\n",
    "            print(\"• Низкий показатель отказов (хорошее качество трафика)\")\n",
    "        if pageval_mean > data['PageValues'].mean():\n",
    "            print(\"• Высокая ценность страниц\")\n",
    "        if revenue_pct > original_data['Revenue'].mean() * 100:\n",
    "            print(\"• Высокая конверсия в покупку\")\n",
    "        \n",
    "        print(\"\\n\" + \"-\"*60)\n",
    "\n",
    "interpret_clusters(features, best_labels, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Заключение и выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ЗАКЛЮЧЕНИЕ И ВЫВОДЫ\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\n1. ЛУЧШИЙ МЕТОД КЛАСТЕРИЗАЦИИ: {best_method_name}\")\n",
    "print(f\"   - Silhouette Score: {best_method['Silhouette Score']:.4f}\")\n",
    "print(f\"   - Calinski-Harabasz Score: {best_method['Calinski-Harabasz Score (R2)']:.4f}\")\n",
    "print(f\"   - Davies-Bouldin Score: {best_method['Davies-Bouldin Score']:.4f}\")\n",
    "\n",
    "print(f\"\\n2. КОЛИЧЕСТВО КЛАСТЕРОВ: {len(np.unique(best_labels))}\")\n",
    "\n",
    "print(f\"\\n3. АНАЛИЗ ФОРМЫ КЛАСТЕРОВ:\")\n",
    "print(f\"   - Rand Index показывает согласованность между методами\")\n",
    "if 'rand_scores' in locals() and rand_scores:\n",
    "    print(f\"   - Средний Rand Index: {np.mean(rand_scores):.4f}\")\n",
    "    if np.mean(rand_scores) > 0.5:\n",
    "        print(f\"   - Высокая согласованность методов → сферическая форма кластеров\")\n",
    "    else:\n",
    "        print(f\"   - Низкая согласованность методов → сложная форма кластеров\")\n",
    "\n",
    "print(f\"\\n4. КАЧЕСТВО КЛАСТЕРИЗАЦИИ:\")\n",
    "if best_method['Silhouette Score'] > 0.5:\n",
    "    print(f\"   - Отличное качество кластеризации (Silhouette > 0.5)\")\n",
    "elif best_method['Silhouette Score'] > 0.3:\n",
    "    print(f\"   - Хорошее качество кластеризации (Silhouette > 0.3)\")\n",
    "else:\n",
    "    print(f\"   - Удовлетворительное качество кластеризации\")\n",
    "\n",
    "print(f\"\\n5. ПРАКТИЧЕСКОЕ ПРИМЕНЕНИЕ:\")\n",
    "print(f\"   - Кластеры позволяют сегментировать пользователей по поведению\")\n",
    "print(f\"   - Можно разработать персонализированные стратегии для каждого сегмента\")\n",
    "print(f\"   - Высококонвертируемые сегменты требуют особого внимания\")\n",
    "print(f\"   - Сегменты с высоким bounce rate нуждаются в улучшении UX\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}