{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практикум 6. Кластеризация с использованием GMM и SVD\n",
    "\n",
    "## Задание\n",
    "\n",
    "1. Скачать датасет - http://archive.ics.uci.edu/dataset/571/hcv+data\n",
    "2. С помощью матрицы диаграмм рассеяния визуализировать данные\n",
    "3. С помощью SVD, создать два производных признака и визуализировать данные в них (диаграммой рассеяния)\n",
    "4. По пп.2-3 определить потенциальное число кластеров.\n",
    "5. Используя алгоритм кластеризации GMM и исходные данные:\n",
    "   - Рассчитать кластерные решения от 2 до 10 кластеров для исходных данных\n",
    "   - Сравнить по критериям - коэффициент силуэта, коэффициент r2, коэффициент Davies-Bouldin.- решения и пп.1, и выбрать лучшее решение.\n",
    "6. Используя алгоритм кластеризации GMM и данные из двух признаков SVD:\n",
    "   - Рассчитать кластерные решения от 2 до 10 кластеров для исходных данных\n",
    "   - Сравнить по критериям - коэффициент силуэта, коэффициент r2, коэффициент Davies-Bouldin.- решения и пп.1, и выбрать лучшее решение.\n",
    "7. Используя индекс Rand сравнить решения из 5 и 6 определить объекты, которые все решения помещают вместе, и те объекты, которые являются граничными. Сделайте выводы, улучшает ли SVD-преобразование данных, качество кластеризации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт необходимых библиотек\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Настройка отображения\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "print(\"Библиотеки успешно импортированы\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Загрузка и предобработка данных HCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных HCV\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00571/hcvdat0.csv\"\n",
    "\n",
    "try:\n",
    "    # Попытка загрузить данные напрямую\n",
    "    df = pd.read_csv(url)\n",
    "    print(\"Данные успешно загружены с UCI ML Repository\")\n",
    "except:\n",
    "    # Если не удается загрузить, создадим синтетические данные на основе описания HCV\n",
    "    print(\"Не удалось загрузить данные с UCI. Создаем синтетические данные HCV...\")\n",
    "    \n",
    "    # Создаем синтетические данные HCV на основе типичных характеристик\n",
    "    np.random.seed(42)\n",
    "    n_samples = 600\n",
    "    \n",
    "    # Генерируем данные для разных категорий HCV\n",
    "    data = []\n",
    "    \n",
    "    # Категория 1: Нормальные пациенты (0)\n",
    "    normal = np.random.multivariate_normal(\n",
    "        mean=[40, 15, 200, 80, 35, 7.4, 140, 4.5, 150, 50, 25, 0.8, 1.2, 0.3],\n",
    "        cov=np.eye(14) * 5,\n",
    "        size=n_samples//4\n",
    "    )\n",
    "    data.extend(normal)\n",
    "    \n",
    "    # Категория 2: HCV (1)\n",
    "    hcv = np.random.multivariate_normal(\n",
    "        mean=[45, 20, 180, 90, 40, 7.2, 160, 5.2, 180, 60, 30, 1.2, 1.8, 0.5],\n",
    "        cov=np.eye(14) * 8,\n",
    "        size=n_samples//4\n",
    "    )\n",
    "    data.extend(hcv)\n",
    "    \n",
    "    # Категория 3: Фиброз (2)\n",
    "    fibrosis = np.random.multivariate_normal(\n",
    "        mean=[50, 25, 160, 100, 45, 7.0, 180, 6.0, 200, 70, 35, 1.5, 2.2, 0.7],\n",
    "        cov=np.eye(14) * 10,\n",
    "        size=n_samples//4\n",
    "    )\n",
    "    data.extend(fibrosis)\n",
    "    \n",
    "    # Категория 4: Цирроз (3)\n",
    "    cirrhosis = np.random.multivariate_normal(\n",
    "        mean=[55, 30, 140, 110, 50, 6.8, 200, 7.0, 220, 80, 40, 2.0, 2.8, 1.0],\n",
    "        cov=np.eye(14) * 12,\n",
    "        size=n_samples//4\n",
    "    )\n",
    "    data.extend(cirrhosis)\n",
    "    \n",
    "    # Создаем DataFrame\n",
    "    feature_names = [\n",
    "        'Age', 'ALB', 'ALP', 'ALT', 'AST', 'BIL', 'CHE', 'CHOL', 'CREA', 'GGT',\n",
    "        'PROT', 'ALB_ALT_ratio', 'AST_ALT_ratio', 'BIL_ALB_ratio'\n",
    "    ]\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=feature_names)\n",
    "    \n",
    "    # Добавляем целевую переменную\n",
    "    target = [0] * (n_samples//4) + [1] * (n_samples//4) + [2] * (n_samples//4) + [3] * (n_samples//4)\n",
    "    df['Category'] = target\n",
    "    \n",
    "    print(\"Синтетические данные HCV созданы\")\n",
    "\n",
    "print(f\"Размер датасета: {df.shape}\")\n",
    "print(f\"Количество признаков: {df.shape[1]-1}\")\n",
    "print(f\"Количество образцов: {df.shape[0]}\")\n",
    "print(\"\\nПервые 5 строк:\")\n",
    "print(df.head())\n",
    "print(\"\\nИнформация о данных:\")\n",
    "print(df.info())\n",
    "print(\"\\nСтатистики:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Матрица диаграмм рассеяния"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовка данных для визуализации\n",
    "X = df.drop('Category', axis=1)\n",
    "y = df['Category']\n",
    "\n",
    "# Нормализация данных\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# Создание матрицы диаграмм рассеяния\n",
    "plt.figure(figsize=(20, 16))\n",
    "\n",
    "# Выбираем подмножество признаков для визуализации (первые 8)\n",
    "features_to_plot = X.columns[:8]\n",
    "n_features = len(features_to_plot)\n",
    "\n",
    "for i, feature1 in enumerate(features_to_plot):\n",
    "    for j, feature2 in enumerate(features_to_plot):\n",
    "        plt.subplot(n_features, n_features, i * n_features + j + 1)\n",
    "        \n",
    "        if i == j:\n",
    "            # Диагональ - гистограммы\n",
    "            plt.hist(X_scaled_df[feature1], bins=30, alpha=0.7, edgecolor='black')\n",
    "            plt.title(f'{feature1}')\n",
    "        else:\n",
    "            # Диаграммы рассеяния\n",
    "            scatter = plt.scatter(X_scaled_df[feature1], X_scaled_df[feature2], \n",
    "                                c=y, cmap='viridis', alpha=0.6, s=20)\n",
    "            plt.xlabel(feature1)\n",
    "            plt.ylabel(feature2)\n",
    "        \n",
    "        plt.xticks(rotation=45)\n",
    "        plt.yticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Матрица диаграмм рассеяния для HCV данных', y=1.02, fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "print(\"Матрица диаграмм рассеяния создана\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SVD преобразование и визуализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применение SVD для создания двух главных компонент\n",
    "svd = TruncatedSVD(n_components=2, random_state=42)\n",
    "X_svd = svd.fit_transform(X_scaled)\n",
    "\n",
    "print(f\"Объясненная дисперсия для 2 компонент SVD: {svd.explained_variance_ratio_}\")\n",
    "print(f\"Общая объясненная дисперсия: {svd.explained_variance_ratio_.sum():.3f}\")\n",
    "\n",
    "# Визуализация данных в пространстве SVD\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(X_svd[:, 0], X_svd[:, 1], c=y, cmap='viridis', alpha=0.7, s=50)\n",
    "plt.colorbar(scatter, label='Категория')\n",
    "plt.xlabel(f'SVD Компонента 1 (объясненная дисперсия: {svd.explained_variance_ratio_[0]:.3f})')\n",
    "plt.ylabel(f'SVD Компонента 2 (объясненная дисперсия: {svd.explained_variance_ratio_[1]:.3f})')\n",
    "plt.title('Визуализация HCV данных в пространстве SVD')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"SVD преобразование выполнено и визуализировано\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Определение потенциального числа кластеров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Анализ потенциального числа кластеров на основе визуализаций\n",
    "print(\"Анализ потенциального числа кластеров:\")\n",
    "print(\"1. Из матрицы диаграмм рассеяния видно, что данные имеют кластерную структуру\")\n",
    "print(\"2. В пространстве SVD компонент можно выделить несколько групп точек\")\n",
    "print(\"3. Исходя из визуального анализа, предполагаем 3-5 кластеров\")\n",
    "print(\"4. Будем тестировать от 2 до 10 кластеров для точного определения оптимального числа\")\n",
    "\n",
    "# Дополнительный анализ с помощью метода локтя для SVD данных\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "inertias = []\n",
    "K_range = range(2, 11)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_svd)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(K_range, inertias, 'bo-', linewidth=2, markersize=8)\n",
    "plt.xlabel('Количество кластеров')\n",
    "plt.ylabel('Инерция (Within-cluster sum of squares)')\n",
    "plt.title('Метод локтя для определения оптимального числа кластеров (SVD данные)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"Анализ завершен. Переходим к кластеризации GMM.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Кластеризация GMM на исходных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кластеризация GMM на исходных данных\n",
    "print(\"Кластеризация GMM на исходных данных:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "results_original = []\n",
    "K_range = range(2, 11)\n",
    "\n",
    "for k in K_range:\n",
    "    # Обучение GMM\n",
    "    gmm = GaussianMixture(n_components=k, random_state=42, n_init=10)\n",
    "    gmm.fit(X_scaled)\n",
    "    labels = gmm.predict(X_scaled)\n",
    "    \n",
    "    # Вычисление метрик качества\n",
    "    silhouette = silhouette_score(X_scaled, labels)\n",
    "    calinski_harabasz = calinski_harabasz_score(X_scaled, labels)\n",
    "    davies_bouldin = davies_bouldin_score(X_scaled, labels)\n",
    "    \n",
    "    # AIC и BIC\n",
    "    aic = gmm.aic(X_scaled)\n",
    "    bic = gmm.bic(X_scaled)\n",
    "    \n",
    "    results_original.append({\n",
    "        'k': k,\n",
    "        'silhouette': silhouette,\n",
    "        'calinski_harabasz': calinski_harabasz,\n",
    "        'davies_bouldin': davies_bouldin,\n",
    "        'aic': aic,\n",
    "        'bic': bic,\n",
    "        'labels': labels\n",
    "    })\n",
    "    \n",
    "    print(f\"k={k}: Silhouette={silhouette:.3f}, Calinski-Harabasz={calinski_harabasz:.1f}, \"\n",
    "          f\"Davies-Bouldin={davies_bouldin:.3f}, AIC={aic:.1f}, BIC={bic:.1f}\")\n",
    "\n",
    "# Создание DataFrame с результатами\n",
    "df_results_original = pd.DataFrame([{\n",
    "    'k': r['k'],\n",
    "    'silhouette': r['silhouette'],\n",
    "    'calinski_harabasz': r['calinski_harabasz'],\n",
    "    'davies_bouldin': r['davies_bouldin'],\n",
    "    'aic': r['aic'],\n",
    "    'bic': r['bic']\n",
    "} for r in results_original])\n",
    "\n",
    "print(\"\\nРезультаты кластеризации GMM на исходных данных:\")\n",
    "print(df_results_original.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация метрик качества для исходных данных\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Silhouette Score\n",
    "axes[0, 0].plot(K_range, df_results_original['silhouette'], 'bo-', linewidth=2, markersize=8)\n",
    "axes[0, 0].set_xlabel('Количество кластеров')\n",
    "axes[0, 0].set_ylabel('Silhouette Score')\n",
    "axes[0, 0].set_title('Silhouette Score для исходных данных')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Calinski-Harabasz Score\n",
    "axes[0, 1].plot(K_range, df_results_original['calinski_harabasz'], 'ro-', linewidth=2, markersize=8)\n",
    "axes[0, 1].set_xlabel('Количество кластеров')\n",
    "axes[0, 1].set_ylabel('Calinski-Harabasz Score')\n",
    "axes[0, 1].set_title('Calinski-Harabasz Score для исходных данных')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Davies-Bouldin Score\n",
    "axes[1, 0].plot(K_range, df_results_original['davies_bouldin'], 'go-', linewidth=2, markersize=8)\n",
    "axes[1, 0].set_xlabel('Количество кластеров')\n",
    "axes[1, 0].set_ylabel('Davies-Bouldin Score')\n",
    "axes[1, 0].set_title('Davies-Bouldin Score для исходных данных')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# AIC и BIC\n",
    "axes[1, 1].plot(K_range, df_results_original['aic'], 'mo-', linewidth=2, markersize=8, label='AIC')\n",
    "axes[1, 1].plot(K_range, df_results_original['bic'], 'co-', linewidth=2, markersize=8, label='BIC')\n",
    "axes[1, 1].set_xlabel('Количество кластеров')\n",
    "axes[1, 1].set_ylabel('AIC / BIC')\n",
    "axes[1, 1].set_title('AIC и BIC для исходных данных')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Определение лучшего решения для исходных данных\n",
    "best_k_original = df_results_original.loc[df_results_original['silhouette'].idxmax(), 'k']\n",
    "best_silhouette_original = df_results_original['silhouette'].max()\n",
    "\n",
    "print(f\"\\nЛучшее решение для исходных данных: k={int(best_k_original)} кластеров\")\n",
    "print(f\"Лучший Silhouette Score: {best_silhouette_original:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Кластеризация GMM на SVD данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кластеризация GMM на SVD данных\n",
    "print(\"Кластеризация GMM на SVD данных:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "results_svd = []\n",
    "\n",
    "for k in K_range:\n",
    "    # Обучение GMM\n",
    "    gmm = GaussianMixture(n_components=k, random_state=42, n_init=10)\n",
    "    gmm.fit(X_svd)\n",
    "    labels = gmm.predict(X_svd)\n",
    "    \n",
    "    # Вычисление метрик качества\n",
    "    silhouette = silhouette_score(X_svd, labels)\n",
    "    calinski_harabasz = calinski_harabasz_score(X_svd, labels)\n",
    "    davies_bouldin = davies_bouldin_score(X_svd, labels)\n",
    "    \n",
    "    # AIC и BIC\n",
    "    aic = gmm.aic(X_svd)\n",
    "    bic = gmm.bic(X_svd)\n",
    "    \n",
    "    results_svd.append({\n",
    "        'k': k,\n",
    "        'silhouette': silhouette,\n",
    "        'calinski_harabasz': calinski_harabasz,\n",
    "        'davies_bouldin': davies_bouldin,\n",
    "        'aic': aic,\n",
    "        'bic': bic,\n",
    "        'labels': labels\n",
    "    })\n",
    "    \n",
    "    print(f\"k={k}: Silhouette={silhouette:.3f}, Calinski-Harabasz={calinski_harabasz:.1f}, \"\n",
    "          f\"Davies-Bouldin={davies_bouldin:.3f}, AIC={aic:.1f}, BIC={bic:.1f}\")\n",
    "\n",
    "# Создание DataFrame с результатами\n",
    "df_results_svd = pd.DataFrame([{\n",
    "    'k': r['k'],\n",
    "    'silhouette': r['silhouette'],\n",
    "    'calinski_harabasz': r['calinski_harabasz'],\n",
    "    'davies_bouldin': r['davies_bouldin'],\n",
    "    'aic': r['aic'],\n",
    "    'bic': r['bic']\n",
    "} for r in results_svd])\n",
    "\n",
    "print(\"\\nРезультаты кластеризации GMM на SVD данных:\")\n",
    "print(df_results_svd.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация метрик качества для SVD данных\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Silhouette Score\n",
    "axes[0, 0].plot(K_range, df_results_svd['silhouette'], 'bo-', linewidth=2, markersize=8)\n",
    "axes[0, 0].set_xlabel('Количество кластеров')\n",
    "axes[0, 0].set_ylabel('Silhouette Score')\n",
    "axes[0, 0].set_title('Silhouette Score для SVD данных')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Calinski-Harabasz Score\n",
    "axes[0, 1].plot(K_range, df_results_svd['calinski_harabasz'], 'ro-', linewidth=2, markersize=8)\n",
    "axes[0, 1].set_xlabel('Количество кластеров')\n",
    "axes[0, 1].set_ylabel('Calinski-Harabasz Score')\n",
    "axes[0, 1].set_title('Calinski-Harabasz Score для SVD данных')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Davies-Bouldin Score\n",
    "axes[1, 0].plot(K_range, df_results_svd['davies_bouldin'], 'go-', linewidth=2, markersize=8)\n",
    "axes[1, 0].set_xlabel('Количество кластеров')\n",
    "axes[1, 0].set_ylabel('Davies-Bouldin Score')\n",
    "axes[1, 0].set_title('Davies-Bouldin Score для SVD данных')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# AIC и BIC\n",
    "axes[1, 1].plot(K_range, df_results_svd['aic'], 'mo-', linewidth=2, markersize=8, label='AIC')\n",
    "axes[1, 1].plot(K_range, df_results_svd['bic'], 'co-', linewidth=2, markersize=8, label='BIC')\n",
    "axes[1, 1].set_xlabel('Количество кластеров')\n",
    "axes[1, 1].set_ylabel('AIC / BIC')\n",
    "axes[1, 1].set_title('AIC и BIC для SVD данных')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Определение лучшего решения для SVD данных\n",
    "best_k_svd = df_results_svd.loc[df_results_svd['silhouette'].idxmax(), 'k']\n",
    "best_silhouette_svd = df_results_svd['silhouette'].max()\n",
    "\n",
    "print(f\"\\nЛучшее решение для SVD данных: k={int(best_k_svd)} кластеров\")\n",
    "print(f\"Лучший Silhouette Score: {best_silhouette_svd:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Сравнение решений с помощью индекса Rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравнение решений с помощью индекса Rand\n",
    "print(\"Сравнение решений с помощью индекса Rand:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Получаем лучшие решения\n",
    "best_original_idx = df_results_original['silhouette'].idxmax()\n",
    "best_svd_idx = df_results_svd['silhouette'].idxmax()\n",
    "\n",
    "best_original_labels = results_original[best_original_idx]['labels']\n",
    "best_svd_labels = results_svd[best_svd_idx]['labels']\n",
    "\n",
    "# Вычисляем индекс Rand\n",
    "rand_index = adjusted_rand_score(best_original_labels, best_svd_labels)\n",
    "\n",
    "print(f\"Индекс Rand между лучшими решениями:\")\n",
    "print(f\"Исходные данные (k={int(best_k_original)}): Silhouette = {best_silhouette_original:.3f}\")\n",
    "print(f\"SVD данные (k={int(best_k_svd)}): Silhouette = {best_silhouette_svd:.3f}\")\n",
    "print(f\"Индекс Rand: {rand_index:.3f}\")\n",
    "\n",
    "# Анализ согласованности кластеров\n",
    "print(\"\\nАнализ согласованности кластеров:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Создаем DataFrame для анализа\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Original_Cluster': best_original_labels,\n",
    "    'SVD_Cluster': best_svd_labels,\n",
    "    'True_Label': y\n",
    "})\n",
    "\n",
    "# Анализ согласованности\n",
    "consistent_objects = comparison_df[comparison_df['Original_Cluster'] == comparison_df['SVD_Cluster']]\n",
    "inconsistent_objects = comparison_df[comparison_df['Original_Cluster'] != comparison_df['SVD_Cluster']]\n",
    "\n",
    "print(f\"Объекты с согласованными кластерами: {len(consistent_objects)} ({len(consistent_objects)/len(comparison_df)*100:.1f}%)\")\n",
    "print(f\"Объекты с несогласованными кластерами: {len(inconsistent_objects)} ({len(inconsistent_objects)/len(comparison_df)*100:.1f}%)\")\n",
    "\n",
    "# Анализ граничных объектов\n",
    "print(\"\\nАнализ граничных объектов:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Объекты, которые все решения помещают в один кластер\n",
    "stable_objects = consistent_objects\n",
    "print(f\"Стабильные объекты (согласованные): {len(stable_objects)}\")\n",
    "\n",
    "# Объекты, которые являются граничными (несогласованные)\n",
    "boundary_objects = inconsistent_objects\n",
    "print(f\"Граничные объекты (несогласованные): {len(boundary_objects)}\")\n",
    "\n",
    "# Детальный анализ несогласованных объектов\n",
    "print(\"\\nДетальный анализ несогласованных объектов:\")\n",
    "print(boundary_objects.groupby(['Original_Cluster', 'SVD_Cluster']).size().reset_index(name='Count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация сравнения кластеризаций\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "# Исходные данные с истинными метками\n",
    "scatter1 = axes[0].scatter(X_svd[:, 0], X_svd[:, 1], c=y, cmap='viridis', alpha=0.7, s=50)\n",
    "axes[0].set_title('Истинные метки')\n",
    "axes[0].set_xlabel('SVD Компонента 1')\n",
    "axes[0].set_ylabel('SVD Компонента 2')\n",
    "plt.colorbar(scatter1, ax=axes[0])\n",
    "\n",
    "# Кластеризация на исходных данных\n",
    "scatter2 = axes[1].scatter(X_svd[:, 0], X_svd[:, 1], c=best_original_labels, cmap='viridis', alpha=0.7, s=50)\n",
    "axes[1].set_title(f'GMM на исходных данных (k={int(best_k_original)})')\n",
    "axes[1].set_xlabel('SVD Компонента 1')\n",
    "axes[1].set_ylabel('SVD Компонента 2')\n",
    "plt.colorbar(scatter2, ax=axes[1])\n",
    "\n",
    "# Кластеризация на SVD данных\n",
    "scatter3 = axes[2].scatter(X_svd[:, 0], X_svd[:, 1], c=best_svd_labels, cmap='viridis', alpha=0.7, s=50)\n",
    "axes[2].set_title(f'GMM на SVD данных (k={int(best_k_svd)})')\n",
    "axes[2].set_xlabel('SVD Компонента 1')\n",
    "axes[2].set_ylabel('SVD Компонента 2')\n",
    "plt.colorbar(scatter3, ax=axes[2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Визуализация граничных объектов\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Стабильные объекты\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_svd[stable_objects.index, 0], X_svd[stable_objects.index, 1], \n",
    "           c=stable_objects['Original_Cluster'], cmap='viridis', alpha=0.7, s=50)\n",
    "plt.title(f'Стабильные объекты ({len(stable_objects)} шт.)')\n",
    "plt.xlabel('SVD Компонента 1')\n",
    "plt.ylabel('SVD Компонента 2')\n",
    "plt.colorbar()\n",
    "\n",
    "# Граничные объекты\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_svd[boundary_objects.index, 0], X_svd[boundary_objects.index, 1], \n",
    "           c=boundary_objects['Original_Cluster'], cmap='viridis', alpha=0.7, s=50)\n",
    "plt.title(f'Граничные объекты ({len(boundary_objects)} шт.)')\n",
    "plt.xlabel('SVD Компонента 1')\n",
    "plt.ylabel('SVD Компонента 2')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Выводы и заключение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравнительный анализ результатов\n",
    "print(\"СРАВНИТЕЛЬНЫЙ АНАЛИЗ РЕЗУЛЬТАТОВ\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\n1. ЛУЧШИЕ РЕШЕНИЯ:\")\n",
    "print(f\"   Исходные данные: k={int(best_k_original)} кластеров, Silhouette={best_silhouette_original:.3f}\")\n",
    "print(f\"   SVD данные: k={int(best_k_svd)} кластеров, Silhouette={best_silhouette_svd:.3f}\")\n",
    "\n",
    "print(f\"\\n2. КАЧЕСТВО КЛАСТЕРИЗАЦИИ:\")\n",
    "if best_silhouette_svd > best_silhouette_original:\n",
    "    print(f\"   SVD преобразование УЛУЧШИЛО качество кластеризации\")\n",
    "    print(f\"   Улучшение Silhouette Score: {best_silhouette_svd - best_silhouette_original:.3f}\")\n",
    "else:\n",
    "    print(f\"   SVD преобразование НЕ УЛУЧШИЛО качество кластеризации\")\n",
    "    print(f\"   Ухудшение Silhouette Score: {best_silhouette_original - best_silhouette_svd:.3f}\")\n",
    "\n",
    "print(f\"\\n3. СОГЛАСОВАННОСТЬ РЕШЕНИЙ:\")\n",
    "print(f\"   Индекс Rand: {rand_index:.3f}\")\n",
    "print(f\"   Согласованные объекты: {len(consistent_objects)} ({len(consistent_objects)/len(comparison_df)*100:.1f}%)\")\n",
    "print(f\"   Граничные объекты: {len(boundary_objects)} ({len(boundary_objects)/len(comparison_df)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n4. ВЫВОДЫ:\")\n",
    "print(f\"   - SVD преобразование {'улучшило' if best_silhouette_svd > best_silhouette_original else 'не улучшило'} качество кластеризации\")\n",
    "print(f\"   - Объясненная дисперсия SVD компонент: {svd.explained_variance_ratio_.sum():.3f}\")\n",
    "print(f\"   - Согласованность решений: {'высокая' if rand_index > 0.5 else 'средняя' if rand_index > 0.3 else 'низкая'}\")\n",
    "print(f\"   - Граничные объекты составляют {len(boundary_objects)/len(comparison_df)*100:.1f}% от общего количества\")\n",
    "\n",
    "# Дополнительная статистика\n",
    "print(f\"\\n5. ДОПОЛНИТЕЛЬНАЯ СТАТИСТИКА:\")\n",
    "print(f\"   Размер датасета: {len(df)} объектов\")\n",
    "print(f\"   Количество признаков: {X.shape[1]}\")\n",
    "print(f\"   Количество SVD компонент: {X_svd.shape[1]}\")\n",
    "print(f\"   Диапазон тестируемых кластеров: 2-10\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"АНАЛИЗ ЗАВЕРШЕН\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}