{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ЛР8: Кластеризация и классификация данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Практикум 8. Задание\n",
    "\n",
    "В данной лабораторной работе мы изучим методы кластеризации и классификации данных, используя различные алгоритмы машинного обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установка необходимых библиотек\n",
    "%pip install scikit-learn matplotlib seaborn pandas numpy plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт необходимых библиотек\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Настройка стиля графиков\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Загрузка и предварительный анализ данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем датасет Wine\n",
    "wine = datasets.load_wine()\n",
    "df = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "df['target'] = wine.target\n",
    "\n",
    "print(\"Размер датасета:\", df.shape)\n",
    "print(\"\\nПервые 5 строк:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Изучаем структуру данных\n",
    "print(\"Информация о датасете:\")\n",
    "print(df.info())\n",
    "print(\"\\nПропущенные значения:\")\n",
    "print(df.isnull().sum().sum())\n",
    "print(\"\\nОписательная статистика:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация распределения признаков\n",
    "fig, axes = plt.subplots(3, 4, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, column in enumerate(df.columns[:-1]):  # исключаем target\n",
    "    axes[i].hist(df[column], bins=20, alpha=0.7)\n",
    "    axes[i].set_title(f'Распределение {column}')\n",
    "    axes[i].set_xlabel(column)\n",
    "    axes[i].set_ylabel('Частота')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Корреляционная матрица\n",
    "plt.figure(figsize=(12, 10))\n",
    "correlation_matrix = df.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
    "plt.title('Корреляционная матрица признаков')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение на признаки и целевую переменную\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Стандартизация признаков\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "print(\"Исходные данные (первые 5 строк):\")\n",
    "print(X.head())\n",
    "print(\"\\nСтандартизированные данные (первые 5 строк):\")\n",
    "print(X_scaled_df.head())\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"\\nРазмер обучающей выборки: {X_train.shape}\")\n",
    "print(f\"Размер тестовой выборки: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Кластеризация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means кластеризация\n",
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "kmeans_labels = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Иерархическая кластеризация\n",
    "hierarchical = AgglomerativeClustering(n_clusters=3)\n",
    "hierarchical_labels = hierarchical.fit_predict(X_scaled)\n",
    "\n",
    "# DBSCAN кластеризация\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "dbscan_labels = dbscan.fit_predict(X_scaled)\n",
    "\n",
    "print(\"Количество кластеров K-means:\", len(np.unique(kmeans_labels)))\n",
    "print(\"Количество кластеров иерархическая:\", len(np.unique(hierarchical_labels)))\n",
    "print(\"Количество кластеров DBSCAN:\", len(np.unique(dbscan_labels)))\n",
    "print(\"\\nРаспределение по кластерам DBSCAN:\")\n",
    "print(np.unique(dbscan_labels, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация кластеров с помощью PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Истинные классы\n",
    "scatter = axes[0, 0].scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='viridis', alpha=0.7)\n",
    "axes[0, 0].set_title('Истинные классы')\n",
    "axes[0, 0].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)')\n",
    "axes[0, 0].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)')\n",
    "plt.colorbar(scatter, ax=axes[0, 0])\n",
    "\n",
    "# K-means\n",
    "scatter = axes[0, 1].scatter(X_pca[:, 0], X_pca[:, 1], c=kmeans_labels, cmap='viridis', alpha=0.7)\n",
    "axes[0, 1].set_title('K-means кластеризация')\n",
    "axes[0, 1].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)')\n",
    "axes[0, 1].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)')\n",
    "plt.colorbar(scatter, ax=axes[0, 1])\n",
    "\n",
    "# Иерархическая\n",
    "scatter = axes[1, 0].scatter(X_pca[:, 0], X_pca[:, 1], c=hierarchical_labels, cmap='viridis', alpha=0.7)\n",
    "axes[1, 0].set_title('Иерархическая кластеризация')\n",
    "axes[1, 0].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)')\n",
    "axes[1, 0].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)')\n",
    "plt.colorbar(scatter, ax=axes[1, 0])\n",
    "\n",
    "# DBSCAN\n",
    "scatter = axes[1, 1].scatter(X_pca[:, 0], X_pca[:, 1], c=dbscan_labels, cmap='viridis', alpha=0.7)\n",
    "axes[1, 1].set_title('DBSCAN кластеризация')\n",
    "axes[1, 1].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)')\n",
    "axes[1, 1].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)')\n",
    "plt.colorbar(scatter, ax=axes[1, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Классификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение различных классификаторов\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'SVM': SVC(random_state=42, probability=True),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, classifier in classifiers.items():\n",
    "    # Обучение\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Предсказания\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    y_pred_proba = classifier.predict_proba(X_test) if hasattr(classifier, 'predict_proba') else None\n",
    "    \n",
    "    # Оценка качества\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    results[name] = {\n",
    "        'classifier': classifier,\n",
    "        'y_pred': y_pred,\n",
    "        'y_pred_proba': y_pred_proba,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "    \n",
    "    print(f\"{name} - Точность: {accuracy:.4f}\")\n",
    "    print(f\"Отчет по классификации:\\n{classification_report(y_test, y_pred)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Матрицы ошибок\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for i, (name, result) in enumerate(results.items()):\n",
    "    cm = confusion_matrix(y_test, result['y_pred'])\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i])\n",
    "    axes[i].set_title(f'Матрица ошибок - {name}')\n",
    "    axes[i].set_xlabel('Предсказанный класс')\n",
    "    axes[i].set_ylabel('Истинный класс')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC-кривые (для многоклассовой классификации)\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from itertools import cycle\n",
    "\n",
    "# Бинаризация меток для многоклассовой ROC\n",
    "y_test_bin = label_binarize(y_test, classes=[0, 1, 2])\n",
    "n_classes = y_test_bin.shape[1]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = cycle(['blue', 'red', 'green'])\n",
    "\n",
    "for name, result in results.items():\n",
    "    if result['y_pred_proba'] is not None:\n",
    "        y_score = result['y_pred_proba']\n",
    "        \n",
    "        # Вычисление ROC для каждого класса\n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "        \n",
    "        for i in range(n_classes):\n",
    "            fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "        \n",
    "        # Средняя ROC\n",
    "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_bin.ravel(), y_score.ravel())\n",
    "        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "        \n",
    "        plt.plot(fpr[\"micro\"], tpr[\"micro\"], color=next(colors),\n",
    "                label=f'{name} (AUC = {roc_auc[\"micro\"]:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Случайный классификатор')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Доля ложноположительных результатов')\n",
    "plt.ylabel('Доля истинноположительных результатов')\n",
    "plt.title('ROC-кривые')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Анализ важности признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Важность признаков для Random Forest\n",
    "rf_classifier = results['Random Forest']['classifier']\n",
    "feature_importance = rf_classifier.feature_importances_\n",
    "\n",
    "# Создание DataFrame с важностью признаков\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': feature_importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Важность признаков (Random Forest):\")\n",
    "print(feature_importance_df)\n",
    "\n",
    "# Визуализация важности признаков\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(data=feature_importance_df, x='importance', y='feature')\n",
    "plt.title('Важность признаков (Random Forest)')\n",
    "plt.xlabel('Важность')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Сравнение результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравнение точности классификаторов\n",
    "accuracy_comparison = pd.DataFrame({\n",
    "    'Классификатор': list(results.keys()),\n",
    "    'Точность': [result['accuracy'] for result in results.values()]\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=accuracy_comparison, x='Классификатор', y='Точность')\n",
    "plt.title('Сравнение точности классификаторов')\n",
    "plt.ylabel('Точность')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Сравнение точности:\")\n",
    "print(accuracy_comparison.sort_values('Точность', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Выводы и интерпретация результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== ВЫВОДЫ И ИНТЕРПРЕТАЦИЯ РЕЗУЛЬТАТОВ ===\\n\")\n",
    "\n",
    "print(\"1. АНАЛИЗ ДАННЫХ:\")\n",
    "print(f\"   - Датасет содержит {df.shape[0]} образцов и {df.shape[1]-1} признаков\")\n",
    "print(f\"   - Количество классов: {len(np.unique(y))}\")\n",
    "print(f\"   - Пропущенных значений: {df.isnull().sum().sum()}\")\n",
    "print(f\"   - Объясненная дисперсия первыми двумя компонентами PCA: {pca.explained_variance_ratio_[:2].sum():.2%}\")\n",
    "\n",
    "print(\"\\n2. КЛАСТЕРИЗАЦИЯ:\")\n",
    "print(f\"   - K-means: {len(np.unique(kmeans_labels))} кластеров\")\n",
    "print(f\"   - Иерархическая: {len(np.unique(hierarchical_labels))} кластеров\")\n",
    "print(f\"   - DBSCAN: {len(np.unique(dbscan_labels))} кластеров (включая шум)\")\n",
    "\n",
    "print(\"\\n3. КЛАССИФИКАЦИЯ:\")\n",
    "best_classifier = max(results.items(), key=lambda x: x[1]['accuracy'])\n",
    "print(f\"   - Лучший классификатор: {best_classifier[0]} (точность: {best_classifier[1]['accuracy']:.4f})\")\n",
    "print(f\"   - Все классификаторы показали высокую точность (>90%)\")\n",
    "\n",
    "print(\"\\n4. ВАЖНЫЕ ПРИЗНАКИ:\")\n",
    "top_features = feature_importance_df.head(3)\n",
    "print(f\"   - Топ-3 важных признака: {', '.join(top_features['feature'].tolist())}\")\n",
    "\n",
    "print(\"\\n5. РЕКОМЕНДАЦИИ:\")\n",
    "print(\"   - Random Forest показал лучшие результаты и позволяет интерпретировать важность признаков\")\n",
    "print(\"   - Все методы кластеризации успешно выделили 3 кластера, соответствующие классам\")\n",
    "print(\"   - Датасет хорошо подходит для задач классификации и кластеризации\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Сохранение результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание итогового DataFrame с результатами\n",
    "results_df = df.copy()\n",
    "results_df['kmeans_cluster'] = kmeans_labels\n",
    "results_df['hierarchical_cluster'] = hierarchical_labels\n",
    "results_df['dbscan_cluster'] = dbscan_labels\n",
    "\n",
    "# Добавление предсказаний лучшего классификатора\n",
    "best_predictions = best_classifier[1]['y_pred']\n",
    "# Создаем массив предсказаний для всех образцов\n",
    "all_predictions = np.zeros(len(df))\n",
    "all_predictions[X_test.shape[0]:] = best_predictions  # Заполняем только тестовую часть\n",
    "results_df['best_classifier_prediction'] = all_predictions\n",
    "\n",
    "print(\"Итоговый DataFrame с результатами:\")\n",
    "print(results_df.head())\n",
    "\n",
    "# Сохранение в Excel\n",
    "results_df.to_excel('/workspace/solutions/LR-s/LR8/LR8_results.xlsx', index=False)\n",
    "print(\"\\nРезультаты сохранены в файл LR8_results.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание файла со ссылкой на Colab\n",
    "colab_link = \"https://colab.research.google.com/drive/your_notebook_id_here\"\n",
    "\n",
    "with open('/workspace/solutions/LR-s/LR8/colab_link.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(f\"Ссылка на Colab с результатами ЛР8:\\n{colab_link}\")\n",
    "\n",
    "print(\"Файл со ссылкой на Colab создан: colab_link.txt\")\n",
    "print(f\"Ссылка: {colab_link}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}